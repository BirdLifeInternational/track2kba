#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
metadata <- metadata %>% rename(Bird_ID = Name)
tracks$Date <- do.call(rbind, str_split(tracks$Date, pattern="T"))[,1]
tracks$Time <- do.call(rbind, str_split(tracks$Time, pattern="T"))[,2]
# join with metadata
tracks <- left_join(tracks, metadata, by="Bird_ID")
# format fields
# tracks <- formatFields(tracks, field_ID = "Bird_ID", field_Lat="lat", field_Lon = "long", field_DateTime = "DateTime")
tracks <- formatFields(tracks, fieldID = "Bird_ID", fieldLat="lat", fieldLon = "long", fieldDate = "Date", fieldTime="Time")
# subset to birds which were tagged in january 2019 (more data)
# TD <- tracks[tracks$ID %in% c("Fentale", "Ertale", "Alimerah", "Chuupa", "Lucy", "Ardi", "Qero"), ]
# subset to all birds tagged in Ethiopia (immatures included)
TD <- tracks[tracks$ID %in% c("Fentale", "Ertale", "Alimerah", "Chuupa", "Lucy", "Ardi", "Qero", "Basaka","Awash","Alolobad","Semera","Dalol","Loma","Lubo","Milli"), ]
# TD <- tracks  # all birds
# TD <- subset(TD, TD$Breed_Site == "Logia") # keep only non-migrating birds
# TD <- subset(TD, TD$Tag_Site == "Logia") # all birds tagged at Logia
# TD <- subset(TD, TD$Tag_Site == "Metehara") # all birds tagged at Logia
# TD <- subset(TD, TD$Breed_Site == "Metehara")
# TD <- tracks
# take only ever nth row (rough downsample)
# TD <- TD %>%
#   filter(row_number() %% 10 == 1)
#
# wgs84 <- CRS('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')
# TDsp <- SpatialPointsDataFrame(SpatialPoints(data.frame(TD$Longitude, TD$Latitude), proj4string=wgs84), data = TD)
# # #
# mapview::mapview(TDsp)
TD$stage <- rep("winter")
TD$stage <- ifelse(TD$ID == "Ardi" & (TD$DateTime > as.Date("2019-01-26") & TD$DateTime < as.Date("2019-08-07") | TD$DateTime > as.Date("2020-01-26")), "mig_breed", TD$stage)
TD$stage <- ifelse(TD$ID == "Ertale" & (TD$DateTime > as.Date("2019-04-24") & TD$DateTime < as.Date("2019-11-13")), "mig_breed", TD$stage)
# filter to only wintering periods for each bird
TD <- TD[TD$stage == "winter", ]
TD <- TD[(month(TD$DateTime) < 3 | month(TD$DateTime) > 10), ]
# project tracks
TD <- projectTracks(TD)
# mapview::mapview(TD)
# get H values ~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~
HVALS <- findScale(TD,
scaleARS = T)
# HVALS <- findScale(TD,
#   scaleARS = T,
#   scalesFPT = c(seq(1, 20, 1), seq(25, 100, 5)))
# HVALS <- findScale(TD,
#   scaleARS = T,
#   scalesFPT = c(.5, seq(1, 20, 1), seq(25, 100, 5)))
HVALS
# colony <- data.frame(Latitude = TD$Tag_lat[1], Longitude = TD$Tag_long[1]) # in this case it's actually the tag site
h <- HVALS$href
# h <- HVALS$scaleARS
KDE <- estSpaceUse(tracks=TD, scale = h, levelUD = 50, polyOut=T)
mapKDE(KDE$UDPolygons)
n <- length(KDE$KDE.Surface)
# ggsave( paste0("C:/Users/Martim Bill/Documents/mIBA_package/figures/egyptian_vultures/indcores_", "h", round(h), "_", "n",n, ".png"), width = 6, height = 8)
# Assess representativeness ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# before <- Sys.time()
repr <- repAssess(TD, KDE=KDE$KDE.Surface, iteration=200, bootTable = T, nCores=2)
represent <- repr
repr
repr[[1]]
## Egyptian vulture test of track2KBA ##
pacman::p_load(dplyr, track2KBA, rnaturalearth, sp, sf, lubridate, stringr, ggplot2)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# metadata <- read.csv("C:/Users/Martim Bill/Documents/mIBA_package/test_data/EGVU_Ethiopia_deployments.csv")
metadata <- readxl::read_xlsx("C:/Users/Martim Bill/Documents/mIBA_package/test_data/EGVU_deployments_Metadata.xlsx")
tracks <- read.csv("C:/Users/Martim Bill/Documents/mIBA_package/test_data/EGVU_winter_locs.csv") # data up to 27th Feb, 2020. Contains all birds wintering in this quarter of africa (including birds tagged in various breeding areas in Europe)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
metadata <- metadata %>% rename(Bird_ID = Name)
tracks$Date <- do.call(rbind, str_split(tracks$Date, pattern="T"))[,1]
tracks$Time <- do.call(rbind, str_split(tracks$Time, pattern="T"))[,2]
# join with metadata
tracks <- left_join(tracks, metadata, by="Bird_ID")
# format fields
# tracks <- formatFields(tracks, field_ID = "Bird_ID", field_Lat="lat", field_Lon = "long", field_DateTime = "DateTime")
tracks <- formatFields(tracks, fieldID = "Bird_ID", fieldLat="lat", fieldLon = "long", fieldDate = "Date", fieldTime="Time")
# subset to birds which were tagged in january 2019 (more data)
# TD <- tracks[tracks$ID %in% c("Fentale", "Ertale", "Alimerah", "Chuupa", "Lucy", "Ardi", "Qero"), ]
# subset to all birds tagged in Ethiopia (immatures included)
TD <- tracks[tracks$ID %in% c("Fentale", "Ertale", "Alimerah", "Chuupa", "Lucy", "Ardi", "Qero", "Basaka","Awash","Alolobad","Semera","Dalol","Loma","Lubo","Milli"), ]
# TD <- tracks  # all birds
# TD <- subset(TD, TD$Breed_Site == "Logia") # keep only non-migrating birds
# TD <- subset(TD, TD$Tag_Site == "Logia") # all birds tagged at Logia
# TD <- subset(TD, TD$Tag_Site == "Metehara") # all birds tagged at Logia
# TD <- subset(TD, TD$Breed_Site == "Metehara")
# TD <- tracks
# take only ever nth row (rough downsample)
# TD <- TD %>%
#   filter(row_number() %% 10 == 1)
#
# wgs84 <- CRS('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')
# TDsp <- SpatialPointsDataFrame(SpatialPoints(data.frame(TD$Longitude, TD$Latitude), proj4string=wgs84), data = TD)
# # #
# mapview::mapview(TDsp)
TD$stage <- rep("winter")
TD$stage <- ifelse(TD$ID == "Ardi" & (TD$DateTime > as.Date("2019-01-26") & TD$DateTime < as.Date("2019-08-07") | TD$DateTime > as.Date("2020-01-26")), "mig_breed", TD$stage)
TD$stage <- ifelse(TD$ID == "Ertale" & (TD$DateTime > as.Date("2019-04-24") & TD$DateTime < as.Date("2019-11-13")), "mig_breed", TD$stage)
# filter to only wintering periods for each bird
TD <- TD[TD$stage == "winter", ]
TD <- TD[(month(TD$DateTime) < 3 | month(TD$DateTime) > 10), ]
# project tracks
TD <- projectTracks(TD)
# mapview::mapview(TD)
# get H values ~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~
HVALS <- findScale(TD,
scaleARS = T)
# HVALS <- findScale(TD,
#   scaleARS = T,
#   scalesFPT = c(seq(1, 20, 1), seq(25, 100, 5)))
# HVALS <- findScale(TD,
#   scaleARS = T,
#   scalesFPT = c(.5, seq(1, 20, 1), seq(25, 100, 5)))
HVALS
# colony <- data.frame(Latitude = TD$Tag_lat[1], Longitude = TD$Tag_long[1]) # in this case it's actually the tag site
h <- HVALS$href
# h <- HVALS$scaleARS
KDE <- estSpaceUse(tracks=TD, scale = h, levelUD = 50, polyOut=T)
mapKDE(KDE$UDPolygons)
n <- length(KDE$KDE.Surface)
# ggsave( paste0("C:/Users/Martim Bill/Documents/mIBA_package/figures/egyptian_vultures/indcores_", "h", round(h), "_", "n",n, ".png"), width = 6, height = 8)
# custom map of individual ranges ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
coordsets <- st_bbox(KDE$UDPolygons)
coordsets[1] <- coordsets[1] + .8
# coordsets[3] <- coordsets[1] + 1
UDPLOT <- ggplot(KDE$UDPolygons) + geom_sf(data=KDE$UDPolygons, aes(col=id), size=1, fill=NA) +
borders("world",fill="grey85", colour="grey20") +
geom_sf(data=KDE$UDPolygons, aes(col=id), size=1, fill=NA) +
geom_sf(data=st_as_sf(TD), aes(col=ID), size=1, fill=NA) +
coord_sf(xlim = c(coordsets$xmin - .9, coordsets$xmax + .1), ylim = c(coordsets$ymin, coordsets$ymax), expand = TRUE) +
theme(
panel.background=element_rect(fill="white", colour="black"),
panel.border = element_rect(colour = "black", fill=NA, size=1),
axis.text=element_text(size=12, color="black"),
axis.title=element_text(size=16)) +
ylab("Latitude") +
xlab("Longitude")
UDPLOT
# ggsave( paste0("C:/Users/Martim Bill/Documents/mIBA_package/figures/egyptian_vultures/forage_indcores_all", "h", round(h), "_", "n",n, ".png"), width = 12, height=6)
# Assess representativeness ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# before <- Sys.time()
repr <- repAssess(TD, KDE=KDE$KDE.Surface, iteration=100, bootTable = T, nCores=2)
# Sys.time() - before
repr
repr
repr[[1]]
# Assess representativeness ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# before <- Sys.time()
repr <- repAssess(TD, KDE=KDE$KDE.Surface, iteration=200, bootTable = T, nCores=2)
represent <- repr
repr
repr[[1]]
for(i in 1:(0.5 * maxSize)){
SS2test <- maxSize - i
bResult <- represent[[2]] %>% filter(SampleSize <= SS2test) ## exclude smallest out-samples
M1 <- stats::nls(
InclusionMean ~ (a*SampleSize)/(1+b*SampleSize),
data = bResult, start = list(a=1, b=0.1)
)
a <- base::summary(M1)$coefficients[1]
b <- base::summary(M1)$coefficients[2]
Asymptote <- (a / b)
Asymptote
bResult$pred <- stats::predict(M1)
## Calculate Representativeness value -------------------------------------
RepresentativeValue <- bResult %>%
group_by(.data$SampleSize) %>%
summarise(
out      = max(.data$pred) / Asymptote*100
) %>%
dplyr::filter(.data$out == max(.data$out))
## Extrapolate relationship past sample size-------------------------------
newResult <- data.frame(SampleSize = seq(1, 100, by = 1))
extrap <- stats::predict(M1, newdata=newResult)
extrap
## plot ##
png(
paste0("C:\\Users\\Martim Bill\\Documents\\mIBA_package\\figures\\repAssess\\asymptote\\", "egyptian_vulture_SS", SS2test, ".png"),
width = 650, height = 575
)
plot(InclusionMean ~ SampleSize,
data = bResult, pch = 16,
cex = 0.5, cex.lab=1.2, cex.axis=1.2, col=scales::alpha("darkgray", 0.3),
ylim = c(0,1), xlim = c(0,max(newResult$SampleSize)),
ylab = "Inclusion", xlab = "Sample Size"
)
lines(extrap, lty=1,lwd=2)
text(
x=0, y=0.99,
paste("maxN = ", SS2test, ", ",
"Asymptote = ", round(Asymptote, 2), "%", ", ",
"Rep. = ", round(RepresentativeValue$out, 1), "%",
sep=""),
cex=2, col="grey35", adj=0
)
dev.off()
}
maxSize <- max(represent[[2]]$SampleSize) + 1
for(i in 1:(0.5 * maxSize)){
SS2test <- maxSize - i
bResult <- represent[[2]] %>% filter(SampleSize <= SS2test) ## exclude smallest out-samples
M1 <- stats::nls(
InclusionMean ~ (a*SampleSize)/(1+b*SampleSize),
data = bResult, start = list(a=1, b=0.1)
)
a <- base::summary(M1)$coefficients[1]
b <- base::summary(M1)$coefficients[2]
Asymptote <- (a / b)
Asymptote
bResult$pred <- stats::predict(M1)
## Calculate Representativeness value -------------------------------------
RepresentativeValue <- bResult %>%
group_by(.data$SampleSize) %>%
summarise(
out      = max(.data$pred) / Asymptote*100
) %>%
dplyr::filter(.data$out == max(.data$out))
## Extrapolate relationship past sample size-------------------------------
newResult <- data.frame(SampleSize = seq(1, 100, by = 1))
extrap <- stats::predict(M1, newdata=newResult)
extrap
## plot ##
png(
paste0("C:\\Users\\Martim Bill\\Documents\\mIBA_package\\figures\\repAssess\\asymptote\\", "egyptian_vulture_SS", SS2test, ".png"),
width = 650, height = 575
)
plot(InclusionMean ~ SampleSize,
data = bResult, pch = 16,
cex = 0.5, cex.lab=1.2, cex.axis=1.2, col=scales::alpha("darkgray", 0.3),
ylim = c(0,1), xlim = c(0,max(newResult$SampleSize)),
ylab = "Inclusion", xlab = "Sample Size"
)
lines(extrap, lty=1,lwd=2)
text(
x=0, y=0.99,
paste("maxN = ", SS2test, ", ",
"Asymptote = ", round(Asymptote, 2), "%", ", ",
"Rep. = ", round(RepresentativeValue$out, 1), "%",
sep=""),
cex=2, col="grey35", adj=0
)
dev.off()
}
maxSize <- max(represent[[2]]$SampleSize) + 1
maxSize
for(i in 1:(0.5 * maxSize)){
SS2test <- maxSize - i
bResult <- represent[[2]] %>% filter(SampleSize <= SS2test) ## exclude smallest out-samples
M1 <- stats::nls(
InclusionMean ~ (a*SampleSize)/(1+b*SampleSize),
data = bResult, start = list(a=1, b=0.1)
)
a <- base::summary(M1)$coefficients[1]
b <- base::summary(M1)$coefficients[2]
Asymptote <- (a / b)
Asymptote
bResult$pred <- stats::predict(M1)
## Calculate Representativeness value -------------------------------------
RepresentativeValue <- bResult %>%
group_by(.data$SampleSize) %>%
summarise(
out      = max(.data$pred) / Asymptote*100
) %>%
dplyr::filter(.data$out == max(.data$out))
## Extrapolate relationship past sample size-------------------------------
newResult <- data.frame(SampleSize = seq(1, 100, by = 1))
extrap <- stats::predict(M1, newdata=newResult)
extrap
## plot ##
png(
paste0("C:\\Users\\Martim Bill\\Documents\\mIBA_package\\figures\\repAssess\\asymptote\\", "egyptian_vulture_SS", SS2test, ".png"),
width = 650, height = 575
)
plot(InclusionMean ~ SampleSize,
data = bResult, pch = 16,
cex = 0.5, cex.lab=1.2, cex.axis=1.2, col=scales::alpha("darkgray", 0.3),
ylim = c(0,1), xlim = c(0,max(newResult$SampleSize)),
ylab = "Inclusion", xlab = "Sample Size"
)
lines(extrap, lty=1,lwd=2)
text(
x=0, y=0.99,
paste("maxN = ", SS2test, ", ",
"Asymptote = ", round(Asymptote, 2), "%", ", ",
"Rep. = ", round(RepresentativeValue$out, 1), "%",
sep=""),
cex=2, col="grey35", adj=0
)
dev.off()
}
### Analysis of Antarctic Fur Seal foraging areas ###
pacman::p_load(dplyr, lubridate, sf, track2KBA, ggplot2)
# load data
# setwd("C:/Users/Martim Bill/Documents/track2iba")
load("C:/Users/Martim Bill/Documents/mIBA_package/all_orig_dev_files/example_data/SG_Seal_FinalData4mIBA_V3.Rdata")
ses <- subset(Data3, Data3$common_name=="SES")
afs <- subset(Data3, Data3$common_name!="SES")
col1 <- subset(afs, afs$SpecificColony=="BirdIsl")
col2 <- subset(afs, afs$SpecificColony=="Husvik")
##########
tracks <- col1
# tracks <- col2
## filter to breeding stage only
tracks <- subset(tracks, tracks$breed_stage=="Breeding")
n_distinct(tracks$track_id)
if(tracks$SpecificColony[1] == "Husvik"){
colony <- data.frame(Longitude = -36.7116, Latitude = -54.18)
} else if (tracks$SpecificColony[1] == "BirdIsl"){
colony <- tracks[1,] %>% dplyr::select(lon_colony,lat_colony) %>%
rename(Longitude=lon_colony,Latitude=lat_colony)
}
colony$Longitude <- as.numeric(colony$Longitude)
colony$Latitude <- as.numeric(colony$Latitude)
######
tracks_form <- formatFields(tracks, fieldID = "track_id", fieldLat="Latitude", fieldLon="Longitude", fieldDateTime="date", cleanDF = F)
str(tracks_form)
### for a dataset with both date and time fields #####
# tracks <- formatFields(tracks, field_id = "track_id", field_lat="latitude", field_lon="longitude", field_date="date_gmt", field_time="time_gmt")
#####
# source("tripSplit.R")
allTrips <- tripSplit(tracks_form, colony=colony, innerBuff = 5, returnBuff = 50, duration=12, rmNonTrip = T)
# Tripmap <- mapTrips(allTrips, colony)
Tripmap <- mapTrips(allTrips[allTrips$ID %in% unique(allTrips$ID)[35:46], ], colony)
# ggsave( "C:/Users/Martim Bill/Documents/mIBA_package/figures/fur_seals/trips.png", width = 8, height=6)
######
# source("tripSummary.R")
# Trips <- subset(allTrips, allTrips$Returns == "Yes" ) # removes some 9 seals
Trips <- allTrips
TripSum <- tripSummary(Trips, colony)
TripSum
frange <- median(TripSum$max_dist)
frange
c(min(TripSum$max_dist), max(TripSum$max_dist))
fdur <- median(na.omit(TripSum$duration))/24
fdur
c(min(na.omit(TripSum$duration)), max(na.omit(TripSum$duration)))/24
###### Identify and filter out duplicate DT stamps #####
Trips_list <- vector(mode="list", dplyr::n_distinct(Trips$ID))
for(i in 1:dplyr::n_distinct(Trips$ID)){
one <- Trips[Trips$ID==unique(Trips$ID)[i], ]
one$duplicated <- duplicated(one$DateTime)
Trips_list[[i]] <- one
}
Trips <- do.call(rbind, Trips_list)
Trips <- Trips[Trips$duplicated == FALSE, ]
## 3. ####
Trips <- projectTracks(dataGroup = Trips, reproject = T)
### findScale (get average foraging range, a list of H-value options, and test whether desired grid cell for kernel estimation makes sense given movement scale/tracking resolution) ~~~~~~~~~~~~~~~
HVALS <- findScale(Trips,
scaleARS = F,
sumTrips = TripSum
)
HVALS
## 5. ####
### estSpaceUse (Produce utilization distributions for each individual) ~~~~~~~~~~~~~~~
h <- HVALS$mag
Trips <- Trips[Trips$ColDist > 5, ] # remove trip start and end points near colony
KDE.Surface <- estSpaceUse(tracks=Trips, scale = h, levelUD = 50, polyOut=T)
# KDE.Surface <- estSpaceUse(tracks=Trips, scale = h, levelUD = 50, polyOut=F)
KDEmap <- mapKDE(KDE.Surface$UDPolygons, colony = colony)
n <- length(KDE.Surface$KDE.Surface)
# ggsave( paste0("C:/Users/Martim Bill/Documents/mIBA_package/figures/fur_seals/indcores_", "h", round(h), "_", "n",n, ".png"), width = 8, height=6)
## 6. ####
### repAssess (Assess representativeness of tracked sample ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# before <- Sys.time()
repr <- repAssess(Trips, KDE=KDE.Surface$KDE.Surface, iteration=100, bootTable = T)
# Sys.time() - before
#
represent <- repr
maxSize <- max(represent[[2]]$SampleSize) + 1
for(i in 1:(0.5 * maxSize)){
SS2test <- maxSize - i
bResult <- represent[[2]] %>% filter(SampleSize <= SS2test) ## exclude smallest out-samples
M1 <- stats::nls(
InclusionMean ~ (a*SampleSize)/(1+b*SampleSize),
data = bResult, start = list(a=1, b=0.1)
)
a <- base::summary(M1)$coefficients[1]
b <- base::summary(M1)$coefficients[2]
Asymptote <- (a / b)
Asymptote
bResult$pred <- stats::predict(M1)
## Calculate Representativeness value -------------------------------------
RepresentativeValue <- bResult %>%
group_by(.data$SampleSize) %>%
summarise(
out      = max(.data$pred) / Asymptote*100
) %>%
dplyr::filter(.data$out == max(.data$out))
## Extrapolate relationship past sample size-------------------------------
newResult <- data.frame(SampleSize = seq(1, 100, by = 1))
extrap <- stats::predict(M1, newdata=newResult)
extrap
## plot ##
png(
paste0("C:\\Users\\Martim Bill\\Documents\\mIBA_package\\figures\\repAssess\\asymptote\\", "furseals_SS", SS2test, ".png"),
width = 650, height = 575
)
plot(InclusionMean ~ SampleSize,
data = bResult, pch = 16,
cex = 0.5, cex.lab=1.2, cex.axis=1.2, col=scales::alpha("darkgray", 0.3),
ylim = c(0,1), xlim = c(0,max(newResult$SampleSize)),
ylab = "Inclusion", xlab = "Sample Size"
)
lines(extrap, lty=1,lwd=2)
text(
x=0, y=0.99,
paste("maxN = ", SS2test, ", ",
"Asymptote = ", round(Asymptote, 2), "%", ", ",
"Rep. = ", round(RepresentativeValue$out, 1), "%",
sep=""),
cex=2, col="grey35", adj=0
)
dev.off()
}
1:(0.5 * maxSize)
maxSize
max(represent[[2]]$SampleSize) + 1
max(represent[[2]]$SampleSize)
SS2test
SS2test <- 117
bResult <- represent[[2]] %>% filter(SampleSize <= SS2test) ## exclude smallest out-samples
M1 <- stats::nls(
InclusionMean ~ (a*SampleSize)/(1+b*SampleSize),
data = bResult, start = list(a=1, b=0.1)
)
a <- base::summary(M1)$coefficients[1]
b <- base::summary(M1)$coefficients[2]
Asymptote <- (a / b)
Asymptote
bResult$pred <- stats::predict(M1)
## Calculate Representativeness value -------------------------------------
RepresentativeValue <- bResult %>%
group_by(.data$SampleSize) %>%
summarise(
out      = max(.data$pred) / Asymptote*100
) %>%
dplyr::filter(.data$out == max(.data$out))
## Extrapolate relationship past sample size-------------------------------
newResult <- data.frame(SampleSize = seq(1, 100, by = 1))
extrap <- stats::predict(M1, newdata=newResult)
extrap
## plot ##
png(
paste0("C:\\Users\\Martim Bill\\Documents\\mIBA_package\\figures\\repAssess\\asymptote\\", "furseals_SS", SS2test, ".png"),
width = 650, height = 575
)
plot(InclusionMean ~ SampleSize,
data = bResult, pch = 16,
cex = 0.5, cex.lab=1.2, cex.axis=1.2, col=scales::alpha("darkgray", 0.3),
ylim = c(0,1), xlim = c(0,max(newResult$SampleSize)),
ylab = "Inclusion", xlab = "Sample Size"
)
lines(extrap, lty=1,lwd=2)
text(
x=0, y=0.99,
paste("maxN = ", SS2test, ", ",
"Asymptote = ", round(Asymptote, 2), "%", ", ",
"Rep. = ", round(RepresentativeValue$out, 1), "%",
sep=""),
cex=2, col="grey35", adj=0
)
dev.off()
max(represent[[2]]$SampleSize) + 1
n
repr[[2]]$SampleSize
max(repr[[2]]$SampleSize)
maxSize <- max(represent[[2]]$SampleSize) + 1
for(i in 1:(0.5 * maxSize)){
SS2test <- maxSize - i
bResult <- represent[[2]] %>% filter(SampleSize <= SS2test) ## exclude smallest out-samples
M1 <- stats::nls(
InclusionMean ~ (a*SampleSize)/(1+b*SampleSize),
data = bResult, start = list(a=1, b=0.1)
)
a <- base::summary(M1)$coefficients[1]
b <- base::summary(M1)$coefficients[2]
Asymptote <- (a / b)
Asymptote
bResult$pred <- stats::predict(M1)
## Calculate Representativeness value -------------------------------------
RepresentativeValue <- bResult %>%
group_by(.data$SampleSize) %>%
summarise(
out      = max(.data$pred) / Asymptote*100
) %>%
dplyr::filter(.data$out == max(.data$out))
## Extrapolate relationship past sample size-------------------------------
newResult <- data.frame(SampleSize = seq(1, 120, by = 1))
extrap <- stats::predict(M1, newdata=newResult)
extrap
## plot ##
png(
paste0("C:\\Users\\Martim Bill\\Documents\\mIBA_package\\figures\\repAssess\\asymptote\\", "furseals_SS", SS2test, ".png"),
width = 650, height = 575
)
plot(InclusionMean ~ SampleSize,
data = bResult, pch = 16,
cex = 0.5, cex.lab=1.2, cex.axis=1.2, col=scales::alpha("darkgray", 0.3),
ylim = c(0,1), xlim = c(0,max(newResult$SampleSize)),
ylab = "Inclusion", xlab = "Sample Size"
)
lines(extrap, lty=1,lwd=2)
text(
x=0, y=0.99,
paste("maxN = ", SS2test, ", ",
"Asymptote = ", round(Asymptote, 2), "%", ", ",
"Rep. = ", round(RepresentativeValue$out, 1), "%",
sep=""),
cex=2, col="grey35", adj=0
)
dev.off()
}
unique(represent[[2]]$SampleSize)
0.5 * maxSize
