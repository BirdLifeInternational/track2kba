paste(names(pks_list[nulls]), collapse=" ")
"no peak found for ID(s)",  paste(names(pks_list[nulls]), collapse=" ")
paste("no peak found for ID(s)",  paste(names(pks_list[nulls]), collapse=" ") )
peakWidth <- 3 # how many points either side of a point to define a peak (STILL NEED TO DEBUG WHEN THIS RESULTS IN NO PEAKS
findPeak <- "first"
# turn rows into list of single row dfs
out_scales_list <- split(out_scales, seq(nrow(out_scales)))
out_scales_list <- setNames(split(out_scales, seq(nrow(out_scales))), rownames(out_scales))
# find all peaks for each individual (m is # of pnts either side of peak that has lower or equal value to focal point)
pks_list <- lapply(out_scales_list, function (x, m = peakWidth){
# x <- unlist(out_scales_list[[4]]) # single-row df to vector
x <- unlist(x, use.names = F) # single-row df to vector
shape <- diff(sign(diff(x, na.pad = FALSE)))
pks <- sapply(which(shape < 0), function(i){
z <- i - m + 1
z <- ifelse(z > 0, z, 1)
w <- i + m + 1
w <- ifelse(w < length(x), w, length(x))
if(all(x[c(z : i, (i + 2) : w)] <= x[i + 1])) return(i + 1) else return(NULL)
})
# steepness around peak
steepness <- unlist( sapply(pks, function(i){
if(length(i) > 0) {
s <- sum(diff(x[(i - m) : i]), abs(diff(x[i : (i + m)]))) }
else { s <- NULL }
return(s)
}) )
pks       <- unlist(pks)    # all peaks
firstpeak <- pks[1]         # first peak
maxpeak   <- pks[pks %in% which( Temp == suppressWarnings(max(Temp[pks])) )] # max peak
steeppeak <- pks[which.max(steepness)] # steepest peak
pk_list <- list(allpeaks=pks, first=firstpeak, max=maxpeak, steep=steeppeak)
return(pk_list)
})
nulls <- unlist( lapply( seq_along(pks_list), function(i) {
return(is.null(pks_list[[i]]$allpeaks))
} ) )
if(length(nulls) > 0) {
message("no peak found for ID(s):",  paste(names(pks_list[nulls]), collapse=" ") )
}
# select only peak type chosen by fxn argument findPeak
ars.scales <- unlist( lapply( seq_along(pks_list), function(i) {
return(pks_list[[i]][[findPeak]])
} ) )
ars.scales
pks
pks_list[[1]]
nulls <- unlist( lapply( pks_list, function(x) { return(is.null(x$allpeaks)) } ) )
nulls
length(nulls) > 0
ars.scales <- unlist( lapply( pks_list, function(x) {
return(x[[findPeak]])
} ) )
ars.scales
# select only peak type chosen by fxn argument findPeak
ars.scales <- unlist( lapply( seq_along(pks_list), function(i) {
return(pks_list[[i]][[findPeak]])
} ) )
ars.scales
peakWidth <- 3 # how many points either side of a point to define a peak (STILL NEED TO DEBUG WHEN THIS RESULTS IN NO PEAKS
findPeak <- "first"
# turn rows into list of single row dfs
out_scales_list <- split(out_scales, seq(nrow(out_scales)))
out_scales_list <- setNames(split(out_scales, seq(nrow(out_scales))), rownames(out_scales))
# find all peaks for each individual (m is # of pnts either side of peak that has lower or equal value to focal point)
pks_list <- lapply(out_scales_list, function (x, m = peakWidth){
# x <- unlist(out_scales_list[[4]]) # single-row df to vector
x <- unlist(x, use.names = F) # single-row df to vector
shape <- diff(sign(diff(x, na.pad = FALSE)))
pks <- sapply(which(shape < 0), function(i){
z <- i - m + 1
z <- ifelse(z > 0, z, 1)
w <- i + m + 1
w <- ifelse(w < length(x), w, length(x))
if(all(x[c(z : i, (i + 2) : w)] <= x[i + 1])) return(i + 1) else return(NULL)
})
# steepness around peak
steepness <- unlist( sapply(pks, function(i){
if(length(i) > 0) {
s <- sum(diff(x[(i - m) : i]), abs(diff(x[i : (i + m)]))) }
else { s <- NULL }
return(s)
}) )
pks       <- unlist(pks)    # all peaks
firstpeak <- pks[1]         # first peak
maxpeak   <- pks[pks %in% which( Temp == suppressWarnings(max(Temp[pks])) )] # max peak
steeppeak <- pks[which.max(steepness)] # steepest peak
pk_list <- list(allpeaks=pks, first=firstpeak, max=maxpeak, steep=steeppeak)
return(pk_list)
})
nulls <- unlist( lapply( pks_list, function(x) { return(is.null(x$allpeaks)) } ) )
if(length(nulls) > 0) {
message("no peak found for ID(s):",  paste(names(pks_list[nulls]), collapse=" ") )
}
# select only peak type chosen by fxn argument findPeak
ars.scales <- unlist( lapply( pks_list, function(x) {
return(x[[findPeak]])
} ) )
ars.scales
HVALS <- findScale(Trips,
ARSscale = T,
Trip_summary = TripSum
)
UIDs <- unique(Trips.Projected$ID)
peakWidth <- 3 # how many points either side of a point to define a peak (STILL NEED TO DEBUG WHEN THIS RESULTS IN NO PEAKS
findPeak <- "first"
# turn rows into list of single row dfs
out_scales_list <- split(out_scales, seq(nrow(out_scales)))
out_scales_list <- setNames(split(out_scales, seq(nrow(out_scales))), rownames(out_scales))
# find all peaks for each individual (m is # of pnts either side of peak that has lower or equal value to focal point)
pks_list <- lapply(out_scales_list, function (x, m = peakWidth){
# x <- unlist(out_scales_list[[4]]) # single-row df to vector
x <- unlist(x, use.names = F) # single-row df to vector
shape <- diff(sign(diff(x, na.pad = FALSE)))
pks <- sapply(which(shape < 0), function(i){
z <- i - m + 1
z <- ifelse(z > 0, z, 1)
w <- i + m + 1
w <- ifelse(w < length(x), w, length(x))
if(all(x[c(z : i, (i + 2) : w)] <= x[i + 1])) return(i + 1) else return(NULL)
})
# steepness around peak
steepness <- unlist( sapply(pks, function(i){
if(length(i) > 0) {
s <- sum(diff(x[(i - m) : i]), abs(diff(x[i : (i + m)]))) }
else { s <- NULL }
return(s)
}) )
pks       <- unlist(pks)    # all peaks
firstpeak <- pks[1]         # first peak
maxpeak   <- pks[pks %in% which( Temp == suppressWarnings(max(Temp[pks])) )] # max peak
steeppeak <- pks[which.max(steepness)] # steepest peak
pk_list <- list(allpeaks=pks, first=firstpeak, max=maxpeak, steep=steeppeak)
return(pk_list)
})
nulls <- unlist( lapply( pks_list, function(x) { return(is.null(x$allpeaks)) } ) )
if(length(nulls) > 0) {
message("no peak found for ID(s):",  paste(names(pks_list[nulls]), collapse=" ") )
}
for(i in 1:length(UIDs))
# select only peak type chosen by fxn argument findPeak
ars.scales <- unlist( lapply( pks_list, function(x) {
return(x[[findPeak]])
} ) )
ars.scales
pks_list
# select only peak type chosen by fxn argument findPeak
ars.scales <- unlist( lapply( pks_list, function(x) {
return(x[[findPeak]])
} ) )
ars.scales
AprScale <- round(median(ars.scales), 2)
AprScale
median(NA)
median(NULL)
median(0)
list(numeric(0))
numeric(0)
median(numeric(0))
HVALS$ARSscale <- AprScale ## add ARS scale to data frame
HVALS$href <- round(href/1000, 2)
HVALS <- data.frame(med_max_dist = ForRangeH$med_max_dist, step_length = round(median(med_displace$value),2), mag = ForRangeH$mag, href = HVALS$href, ARSscale = HVALS$ARSscale)
HVALS
undebug(findScale)
HVALS <- findScale(Trips,
ARSscale = F,
Trip_summary = TripSum
)
HVALS <- findScale(Trips,
ARSscale = T,
Trip_summary = TripSum
)
HVALS
debug(findScale)
HVALS <- findScale(Trips,
ARSscale = T,
Trip_summary = TripSum
)
function(DataGroup, ARSscale=T, Res=100, Trip_summary=NULL, FPTscales = NULL, plotPeaks = FALSE, findPeak = "Flexible") {
##################################################################
### CREATE PROJECTED DATAFRAME ###  ***** NEED TO ADD CLEAN TRACKS BIT
if(class(DataGroup)!= "SpatialPointsDataFrame")     ## convert to SpatialPointsDataFrame and project
{
if(!"Latitude" %in% names(DataGroup)) stop("Latitude field does not exist")
if(!"Longitude" %in% names(DataGroup)) stop("Longitude field does not exist")
## set the minimum fields that are needed
mid_point <- data.frame(geosphere::centroid(cbind(DataGroup$Longitude, DataGroup$Latitude)))
### PREVENT PROJECTION PROBLEMS FOR DATA SPANNING DATELINE
if (min(DataGroup$Longitude) < -170 &  max(DataGroup$Longitude) > 170) {
longs = ifelse(DataGroup$Longitude < 0, DataGroup$Longitude + 360, DataGroup$Longitude)
mid_point$lon <- ifelse(median(longs) > 180, median(longs) - 360, median(longs))}
DataGroup.Wgs <- SpatialPoints(data.frame(DataGroup$Longitude, DataGroup$Latitude), proj4string=CRS("+proj=longlat + datum=wgs84"))
proj.UTM <- CRS(paste("+proj=laea +lon_0=", mid_point$lon, " +lat_0=", mid_point$lat, sep=""))
DataGroup.Projected <- spTransform(DataGroup.Wgs, CRS=proj.UTM )
Trips.Projected <- SpatialPointsDataFrame(DataGroup.Projected, data = DataGroup)
}else{   ## if data are already in a SpatialPointsDataFrame then check for projection
if(is.projected(DataGroup)){
Trips.Projected <- DataGroup
}else{ ## if not projected, project data to UTM
if(!"Latitude" %in% names(DataGroup)) stop("Latitude field does not exist")
if(!"Longitude" %in% names(DataGroup)) stop("Longitude field does not exist")
mid_point <- data.frame(geosphere::centroid(cbind(DataGroup@data$Longitude, DataGroup@data$Latitude)))
### PREVENT PROJECTION PROBLEMS FOR DATA SPANNING DATELINE
if (min(DataGroup@data$Longitude) < -170 &  max(DataGroup@data$Longitude) > 170) {
longs = ifelse(DataGroup@data$Longitude < 0, DataGroup@data$Longitude + 360,DataGroup@data$Longitude)
mid_point$lon<-ifelse(median(longs) > 180, median(longs)-360, median(longs))}
proj.UTM <- CRS(paste("+proj=laea +lon_0=", mid_point$lon, " +lat_0=", mid_point$lat, sep=""))
Trips.Projected <- sp::spTransform(DataGroup, CRS=proj.UTM)
}
}
#### prep data frame to fill ####
HVALS <- data.frame(
href=0,
ARSscale=0,
stringsAsFactors=F
)
##################################################################
#### Calculate href for each ID, then get average for dataset ####
##################################################################
IDs <- unique(Trips.Projected$ID)
href_list <- vector(mode="list", length(IDs))
for(i in 1:length(IDs)){
one <- subset(Trips.Projected, Trips.Projected$ID==IDs[i])
xy <- coordinates(one)
varx <- stats::var(xy[, 1])
vary <- stats::var(xy[, 2])
sdxy <- sqrt(0.5 * (varx + vary))
n <- nrow(xy)
ex <- (-1/6)
href_list[[i]] <- sdxy * (n^ex)
}
hrefs <- do.call(rbind, href_list)
href <- mean(hrefs)
##################################################################
##### calculate mean foraging range ####
##################################################################
### Use tripSummary
if(is.null(Trip_summary)){
warning("As no Trip_summary was supplied, the foraging range, and mag, cannot be calculated.")
ForRangeH <- data.frame(med_max_dist = NA, mag = NA)
max_dist <- 0
} else {
ForRangeH <- Trip_summary %>%
ungroup() %>%
summarise(med_max_dist = round(median(.data$max_dist), 2),
mag = round(log(.data$med_max_dist), 2)
)
max_dist <- max(Trip_summary$max_dist)
}
## Calculate median step length in data ##
poss_dist <- purrr::possibly(geosphere::distm, otherwise = NA)
if("trip_id" %in% names(DataGroup)){
grouped <- as.data.frame(Trips.Projected@data) %>%
tidyr::nest(coords=c(.data$Longitude, .data$Latitude)) %>%
group_by(.data$ID, .data$trip_id)
} else {
grouped <- as.data.frame(Trips.Projected@data) %>%
tidyr::nest(coords=c(.data$Longitude, .data$Latitude)) %>%
group_by(.data$ID)
}
## all summary in one pipe
med_displace <- grouped %>%
mutate(prev_coords = dplyr::lag(.data$coords)) %>%
mutate(Dist = purrr::map2_dbl(.data$coords, .data$prev_coords, poss_dist)) %>%
dplyr::summarise(value = round(median(na.omit(.data$Dist)), 2) / 1000) ## convert to km
##################################################################
##### calculate scale of ARS ####
##################################################################
if(ARSscale == T){
if(!"ID" %in% names(Trips.Projected)) stop("ARSscale error: ID field does not exist")
if(!"DateTime" %in% names(Trips.Projected)) stop("ARSscale error: DateTime field exist")
if(!"Latitude" %in% names(Trips.Projected)) stop("ARSscale error: Latitude field does not exist")
if(!"Longitude" %in% names(Trips.Projected)) stop("ARSscale error: Longitude field does not exist")
Trips.Projected$X <- Trips.Projected@coords[,1]
Trips.Projected$Y <- Trips.Projected@coords[,2]
if(is.factor(Trips.Projected@data$ID)==T){Trips.Projected@data$ID <- droplevels(Trips.Projected@data$ID)}
Tripslt <- adehabitatLT::as.ltraj(data.frame(Trips.Projected$X, Trips.Projected$Y), date=Trips.Projected$DateTime, id=Trips.Projected$ID, typeII = TRUE)
##################################################
### Determination of FPTscales ###
##################################################
# Relating the scale of movement in data to the user's desired Res value
minX <- min(coordinates(Trips.Projected)[,1])
maxX <- max(coordinates(Trips.Projected)[,1])
minY <- min(coordinates(Trips.Projected)[,2])
maxY <- max(coordinates(Trips.Projected)[,2])
if(Res > 99){Res <- (max(abs(minX - maxX) / 500,
abs(minY - maxY) / 500)) / 1000
warning(sprintf("No grid resolution ('Res') was specified, or the specified resolution was >99 km and therefore ignored. Movement scale in the data was compared to a 500-cell grid with cell size of %s km squared.", round(Res, 3)), immediate. = TRUE)}
minScale <- max(0.5, quantile(med_displace$value, 0.25))
if(minScale > 20) {minScale <- 20
warning("The average between-point displacement in your data is greater than 20km. Data at this resolution are likely inappropriate for identifying Area-Restricted Search behavior. Consider using another Scale parameter method (e.g. Href).")
} ## set 20km as absolute minimum start point for FPTscales
if (minScale < Res*0.1228){warning("Your chosen grid cell size (i.e. 'Res') is very large compared to the scale of movement in your data. To avoid encompassing space use patterns in very few cells later on, consider reducing 'Res'.", immediate. = TRUE)}
if(!is.null(Trip_summary) & (!is.na(max_dist) & max_dist < 200) ) {maxScale <- max(Trip_summary$max_dist)} else {maxScale <- 200}
### FPTscales NEED TO BE SET DEPENDING ON DATASET - THIS CAN FAIL IF MAXDIST <100 so we need to set this vector conditional on maxdist
### Setting the end of one seq() call the same number as the start of another, creates two of this value. However, Steffen changed to this in response to an error
if(is.null(FPTscales)){
if(maxScale<20){FPTscales <- c(seq(minScale, maxScale, by = max(0.5, quantile(med_displace$value, 0.25))))}
if(maxScale>=20 & maxScale<50){FPTscales <- c(seq(minScale, 20,
by = max(0.5, quantile(med_displace$value, 0.25))),
seq(20, maxScale,
by = max(1, quantile(med_displace$value, 0.5))))}
if(maxScale>=50 & maxScale<100){FPTscales <- c(seq(minScale, 20,
by = max(0.5, quantile(med_displace$value, 0.25))),
seq(21, 50,
by = max(1, quantile(med_displace$value, 0.5))),
seq(50, maxScale,
by = max(5, quantile(med_displace$value, 0.75))))}
if(maxScale>100){FPTscales <- c(seq(minScale, 20,
by = max(0.5, quantile(med_displace$value, 0.25))),
seq(21, 50,
by = max(1, quantile(med_displace$value, 0.5))),
seq(55, 100,
by = max(5, quantile(med_displace$value, 0.75))),
seq(100, maxScale,
by = max(10, quantile(med_displace$value, 0.9))))}
FPTscales <- unique(FPTscales) ## remove duplicated values
}
## FPT analysis
fpt.out <- adehabitatLT::fpt(Tripslt, radii = FPTscales, units = "seconds")
out_scales <- adehabitatLT::varlogfpt(fpt.out, graph = FALSE)
Temp <- as.double(out_scales[1,])
#plot(Scales, Temp, type="l", ylim=c(0, max(out_scales, na.rm=T)))
Tripslt<-NULL
fpt.out<-NULL
ars.scales <- NULL
UIDs <- unique(Trips.Projected$ID)
for(i in 1:length(UIDs))
{
if(length(FPTscales) == length(which(is.na(out_scales[i,])))) {print(paste("Warning: ID", UIDs[i], "is smaller than smallest Scale and will be ignored")); next}
Temp <- as.double(out_scales[i,])
# lines(FPTscales,Temp)
if(plotPeaks == TRUE){
plot(FPTscales, Temp, type="l", main=paste("ID:", UIDs[i]))
}
q <- which(!is.na(Temp))
p <- 2
while(!is.na(Temp[q[p]]) & Temp[q[p]] < Temp[q[p-1]] & q[p] != length(Temp)) {p <- p + 1}
while(!is.na(Temp[q[p]]) & Temp[q[p]] > Temp[q[p-1]]) {p <- p + 1}
rfpt <- FPTscales[q[p-1]]
if(suppressWarnings(min(which(is.na(Temp))) == p)) {print(paste("No peak was found for:", "ID", UIDs[i])); next}
FirstPeak <- FPTscales[q[p-1]]
MaxPeak <- FPTscales[which(Temp == max(Temp[q[p-1]:length(Temp)], na.rm=T))]
if( (FirstPeak==FPTscales[length(FPTscales)-1]) && (FirstPeak == MaxPeak) ) {{print(paste("No peak was found for:", "ID", UIDs[i])); next}}
if(findPeak == "Flexible")  #MB# what is this part doing?
{
if(FirstPeak < MaxPeak[1])
{
MaxPeak <- MaxPeak[MaxPeak >= FirstPeak]
ifelse(MaxPeak[1] < FirstPeak + (max(FPTscales)/3), ars.sc <- MaxPeak[1], ars.sc <- FirstPeak)
}  else  {ars.sc <- FirstPeak}
} else if(findPeak == "First"){
ars.sc <- FirstPeak
} else if(findPeak == "User"){
print("Select peak on Graph")
N <- identify(FPTscales, Temp, n=1)
ars.sc <- FPTscales[N]
}
if(plotPeaks == TRUE){
abline(v=ars.sc, col="red", lty=2)
}
ars.scales <- c(ars.scales, ars.sc)
#print(ars.sc)
#readline("proceed?")
}
if(!is.null(ars.scales)){
AprScale <- round(median(ars.scales), 2)
} else { warning("No peaks found for any individuals. Try changing 'FPTscales' input, or use another h value.")}
if(plotPeaks == TRUE){
plot((FPTscales), Temp, type="l", ylim=c(0, max(out_scales, na.rm=T)), xlab="Scales (km)", ylab="Variance in first passage time")
}
for(i in 1:length(UIDs))
{
Temp <- as.double(out_scales[i,])
if(plotPeaks == TRUE){lines((FPTscales),Temp)}
}
if(plotPeaks == TRUE){
abline(v=ars.scales, col="red", lty=2)
abline(v=AprScale, col="darkred", lty=1, lwd=3)
text(max(FPTscales)/2, 1, paste(AprScale, "km"), col="darkred", cex=3)
}
HVALS$ARSscale <- AprScale ## add ARS scale to data frame
} else {HVALS$ARSscale <- NA}
##################################################################
######### Compile dataframe
HVALS$href <- round(href/1000, 2)
HVALS <- data.frame(med_max_dist = ForRangeH$med_max_dist, step_length = round(median(med_displace$value),2), mag = ForRangeH$mag, href = HVALS$href, ARSscale = HVALS$ARSscale)
# HVALS <- cbind.data.frame(HVALS, ForRangeH) %>%
#   dplyr::select(.data$med_max_dist, .data$mag, .data$href, .data$ARSscale)
return(HVALS)
}
UIDs <- unique(Trips.Projected$ID)
peakWidth <- 3 # how many points either side of a point to define a peak (STILL NEED TO DEBUG WHEN THIS RESULTS IN NO PEAKS
findPeak <- "first"
# turn rows into list of single row dfs
out_scales_list <- split(out_scales, seq(nrow(out_scales)))
out_scales_list <- setNames(split(out_scales, seq(nrow(out_scales))), rownames(out_scales))
# find all peaks for each individual (m is # of pnts either side of peak that has lower or equal value to focal point)
pks_list <- lapply(out_scales_list, function (x, m = peakWidth){
# x <- unlist(out_scales_list[[4]]) # single-row df to vector
x <- unlist(x, use.names = F) # single-row df to vector
shape <- diff(sign(diff(x, na.pad = FALSE)))
pks <- sapply(which(shape < 0), function(i){
z <- i - m + 1
z <- ifelse(z > 0, z, 1)
w <- i + m + 1
w <- ifelse(w < length(x), w, length(x))
if(all(x[c(z : i, (i + 2) : w)] <= x[i + 1])) return(i + 1) else return(NULL)
})
# steepness around peak
steepness <- unlist( sapply(pks, function(i){
if(length(i) > 0) {
s <- sum(diff(x[(i - m) : i]), abs(diff(x[i : (i + m)]))) }
else { s <- NULL }
return(s)
}) )
pks       <- unlist(pks)    # all peaks
firstpeak <- pks[1]         # first peak
maxpeak   <- pks[pks %in% which( Temp == suppressWarnings(max(Temp[pks])) )] # max peak
steeppeak <- pks[which.max(steepness)] # steepest peak
pk_list <- list(allpeaks=pks, first=firstpeak, max=maxpeak, steep=steeppeak)
return(pk_list)
})
nulls <- unlist( lapply( pks_list, function(x) { return(is.null(x$allpeaks)) } ) )
nulls <- unlist( lapply( pks_list, function(x) { return(is.null(x$allpeaks)) } ) )
# select only peak type chosen by fxn argument findPeak
ars.scales <- unlist( lapply( pks_list, function(x) {
return(x[[findPeak]])
} ) )
ars.scales
AprScale <- round(median(ars.scales), 2)
HVALS$ARSscale <- AprScale ## add ARS scale to data frame
HVALS$href <- round(href/1000, 2)
HVALS <- data.frame(med_max_dist = ForRangeH$med_max_dist, step_length = round(median(med_displace$value),2), mag = ForRangeH$mag, href = HVALS$href, ARSscale = HVALS$ARSscale)
HVALS
peakWidth <- 1 # how many points either side of a point to define a peak (STILL NEED TO DEBUG WHEN THIS RESULTS IN NO PEAKS
findPeak <- "first"
# turn rows into list of single row dfs
out_scales_list <- split(out_scales, seq(nrow(out_scales)))
out_scales_list <- setNames(split(out_scales, seq(nrow(out_scales))), rownames(out_scales))
# find all peaks for each individual (m is # of pnts either side of peak that has lower or equal value to focal point)
pks_list <- lapply(out_scales_list, function (x, m = peakWidth){
# x <- unlist(out_scales_list[[4]]) # single-row df to vector
x <- unlist(x, use.names = F) # single-row df to vector
shape <- diff(sign(diff(x, na.pad = FALSE)))
pks <- sapply(which(shape < 0), function(i){
z <- i - m + 1
z <- ifelse(z > 0, z, 1)
w <- i + m + 1
w <- ifelse(w < length(x), w, length(x))
if(all(x[c(z : i, (i + 2) : w)] <= x[i + 1])) return(i + 1) else return(NULL)
})
# steepness around peak
steepness <- unlist( sapply(pks, function(i){
if(length(i) > 0) {
s <- sum(diff(x[(i - m) : i]), abs(diff(x[i : (i + m)]))) }
else { s <- NULL }
return(s)
}) )
pks       <- unlist(pks)    # all peaks
firstpeak <- pks[1]         # first peak
maxpeak   <- pks[pks %in% which( Temp == suppressWarnings(max(Temp[pks])) )] # max peak
steeppeak <- pks[which.max(steepness)] # steepest peak
pk_list <- list(allpeaks=pks, first=firstpeak, max=maxpeak, steep=steeppeak)
return(pk_list)
})
nulls <- unlist( lapply( pks_list, function(x) { return(is.null(x$allpeaks)) } ) )
# select only peak type chosen by fxn argument findPeak
ars.scales <- unlist( lapply( pks_list, function(x) {
return(x[[findPeak]])
} ) )
ars.scales
AprScale <- round(median(ars.scales), 2)
HVALS$ARSscale <- AprScale ## add ARS scale to data frame
HVALS$href <- round(href/1000, 2)
HVALS <- data.frame(med_max_dist = ForRangeH$med_max_dist, step_length = round(median(med_displace$value),2), mag = ForRangeH$mag, href = HVALS$href, ARSscale = HVALS$ARSscale)
HVALS
HVALS <- findScale(Trips,
ARSscale = T,
Trip_summary = TripSum
)
AprScale
ars.scales
FPTscales
length(which(is.na(out_scales[1,])))
length(which(is.na(out_scales[2,])))
?findScale
library(track2KBA)
findScale
HVALS <- findScale(Trips,
ARSscale = T,
Trip_summary = TripSum
)
library(track2KBA)
HVALS <- findScale(Trips,
ARSscale = T,
Trip_summary = TripSum
)
HVALS
cyclocomp_q(findScale())
cyclocomp_q(findScale
)
cyclocomp(findScale())
cyclocomp(findScale) ## HIGH, gets warning from gp()
## assess cyclomatic complexity of each function 1-10 desirable, 10-20 OK, 20-50 too complex, 50+ impossible##
cyclocomp(formatFields)
cyclocomp(tripSplit)
cyclocomp(tripSummary)
cyclocomp(findScale) ## HIGH, gets warning from gp()
cyclocomp(IndEffectTest)
cyclocomp(estSpaceUse)
cyclocomp(findKBA)
