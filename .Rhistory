if(!"Longitude" %in% names(DataGroup)) stop("Longitude field does not exist")
mid_point <- data.frame(geosphere::centroid(cbind(DataGroup@data$Longitude, DataGroup@data$Latitude)))
### PREVENT PROJECTION PROBLEMS FOR DATA SPANNING DATELINE
if (min(DataGroup@data$Longitude) < -170 &  max(DataGroup@data$Longitude) > 170) {
longs = ifelse(DataGroup@data$Longitude < 0, DataGroup@data$Longitude + 360,DataGroup@data$Longitude)
mid_point$lon<-ifelse(median(longs) > 180, median(longs)-360, median(longs))}
proj.UTM <- CRS(paste("+proj=laea +lon_0=", mid_point$lon, " +lat_0=", mid_point$lat, sep=""))
TripCoords <- sp::spTransform(DataGroup, CRS=proj.UTM)
TripCoords@data <- TripCoords@data %>% dplyr::select(ID)
}
}
UIDs <- unique(TripCoords$ID)
NIDs <- length(UIDs)
if(NIDs<50){Nloop <- seq(1, (NIDs - 1), 1)}
if(NIDs>=50 & NIDs<100){Nloop <- c(seq(1, 19, 1), seq(20, (NIDs - 1), 3))}
if(NIDs>=100){Nloop <- c(seq(1, 20, 1), seq(21, 49, 3), seq(50, (NIDs - 1), 6))}
DoubleLoop <- data.frame(SampleSize = rep(Nloop, each=Iteration), Iteration=rep(seq(1:Iteration), length(Nloop)))
LoopNr <- seq(1:dim(DoubleLoop)[1])
# Determine class of KDE, and convert to Raster
if(is.null(KDE)){
if(is.null(Res)) { Res <- 100 }
KDE.Surface <- estSpaceUse(DataGroup=TripCoords, Scale = Scale, Res = Res, UDLev = 50, polyOut=F)
KDEraster <- stack(lapply(KDE.Surface, function(x) raster::raster(x, values=T)))
} else if(class(KDE) == "list") {
KDE.Surface <- KDE$KDE.Surface
KDEraster <- stack(lapply(KDE.Surface, function(x) raster::raster(x, values=T)))
} else {
KDE.Surface <- KDE
KDEraster <- stack(lapply(KDE, function(x) raster(as(x,"SpatialPixelsDataFrame"), values=T)))
# KDEraster <- raster::stack(KDE.Surface)
}
# convert estSpaceUse output (list of estUDs) to RasterLayer list
# KDEraster <- lapply(KDE.Surface, function(x) raster::raster(x, values=T))
###
Result <- data.frame()
Result <- foreach::foreach(LoopN = LoopNr, .combine = rbind, .packages = c("sp", "dplyr", "raster")) %do% {
N <- DoubleLoop$SampleSize[LoopN]
i <- DoubleLoop$Iteration[LoopN]
Output <- data.frame(SampleSize = N, InclusionMean = 0,Iteration=i)
RanNum <- sample(UIDs, N, replace=F)
outIDs <- UIDs[!UIDs %in% RanNum]
# NotSelected <- TripCoords[!TripCoords$ID %in% RanNum, ]
if(all(stringr::str_detect(names(KDEraster), pattern = "^X"))){
NotSelected <- KDEraster[[paste("X", outIDs, sep = "")]]
} else {
NotSelected <- KDEraster[[ outIDs ]]
}
if(all(stringr::str_detect(names(KDEraster), pattern = "^X"))){
Selected <- KDEraster[[paste("X", RanNum, sep = "")]]
} else {
Selected <- KDEraster[[ RanNum ]]
}
# KDEstack <- raster::stack(Selected)  # list of RasterLayers to RasterStack
KDEstack <- Selected
KDEcmbnd <- raster::calc(KDEstack, mean)  # average together individual UDs
KDEstackA <- Selected
KDEstackB <- NotSelected
KDEcmbndA <- raster::calc(KDEstackA, mean)  # average together individual UDs
KDEcmbndB <- raster::calc(KDEstackB, mean)  # average together individual UDs
### Calculating inclusion value, using Kernel surface ######
KDElev <- KDEcmbnd
pixArea <- res(KDElev)[1]
df <- data.frame(UD = getValues(KDElev)) %>%
mutate(rowname = 1:length(getValues(KDElev))) %>%
mutate(usage = .data$UD * (pixArea^2)) %>%
arrange(desc(.data$usage)) %>%
mutate(cumulUD = cumsum(.data$usage)) %>%
mutate(INSIDE = ifelse(.data$cumulUD < 0.5, 1, NA)) %>%
arrange(.data$rowname) %>%
dplyr::select(.data$INSIDE)
KDElev[] <- df$INSIDE
# plot(KDElev)
Overlain_Raster <- raster::extract(KDElev, NotSelected)
Output$InclusionMean <- length(which(!is.na(Overlain_Raster)))/nrow(NotSelected)
return(Output)
}
if(BootTable==T){
write.csv(Result,"bootout_temp.csv", row.names=F)
}
try(M1 <- stats::nls((Result$InclusionMean ~ (a*Result$SampleSize)/(1+b*Result$SampleSize)), data=Result, start=list(a=1,b=0.1)), silent = TRUE)
if ('M1' %in% ls()){       ### run this only if nls was successful
Asymptote <- (base::summary(M1)$coefficients[1] / summary(M1)$coefficients[2])
Result$pred <- stats::predict(M1)
## Calculate RepresentativeValue
RepresentativeValue <- Result %>%
group_by(SampleSize) %>%
summarise(out = max(pred) / ifelse(Asymptote < 0.45, 0.5, Asymptote)*100) %>%
dplyr::filter(out == max(.data$out)) %>%
mutate(type = ifelse(Asymptote < 0.45, 'asymptote_adj', 'asymptote')) %>%
mutate(asym = Asymptote)
if(Asymptote < 0.45) {
RepresentativeValue$asym_adj <- 0.5 }
## Plot
P2 <- Result %>%
group_by(.data$SampleSize) %>%
dplyr::summarise(
meanPred = mean(na.omit(.data$pred)),
sdInclude = sd(.data$InclusionMean))
yTemp <- c(P2$meanPred + 0.5 * P2$sdInclude, rev(P2$meanPred - 0.5 * P2$sdInclude))
xTemp <- c(P2$SampleSize, rev(P2$SampleSize))
# pdf("track2kba_repAssess_output.pdf", width=6, height=5)  ## avoids the plotting margins error
print(plot(InclusionMean ~ SampleSize,
data = Result, pch = 16, cex = 0.2, col="darkgray", ylim = c(0,1), xlim = c(0,max(unique(Result$SampleSize))), ylab = "Inclusion", xlab = "Sample Size"))
polygon(x = xTemp, y = yTemp, col = "gray93", border = F)
points(InclusionMean ~ SampleSize, data=Result, pch=16, cex=0.2, col="darkgray")
lines(P2, lty=1,lwd=2)
text(x=0, y=0.99, paste(round(RepresentativeValue$out, 2), "%", sep=""), cex=2, col="gray45", adj=0)
# dev.off()
}else{ ### if nls is unsuccessful then use mean output for largest sample size
RepresentativeValue <- Result %>%
dplyr::filter(SampleSize == max(.data$SampleSize)) %>%
group_by(.data$SampleSize) %>%
summarise(out = mean(.data$InclusionMean)) %>%
mutate(type = 'inclusion') %>%
mutate(asym = .data$out)
}
print(ifelse(exists("M1"),"nls (non linear regression) successful, asymptote estimated for bootstrap sample.",
"WARNING: nls (non linear regression) unsuccessful, likely due to 'singular gradient', which means there is no asymptote. Data may not be representative, output derived from mean inclusion value at highest sample size. Check bootstrap output csv file"))
return(as.data.frame(RepresentativeValue))
}
cores <- c(1, 2, 3, 4, 5, 10)
durations <- list()
for(i in 1:length(cores)){
cs <- cores[i]
print(cs)
before <- Sys.time()
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=5, Ncores = cs,  BootTable = F)
time <- Sys.time() - before
durations[[i]] <- time
}
durs <- cbind(cores, do.call(rbind, durations))
repAssess <- function(DataGroup, KDE=NULL, Iteration=50, Scale=NULL, Res=NULL, avgMethod = "mean", Ncores=1, BootTable=FALSE){
pkgs <- c('sp', 'geosphere', 'adehabitatHR','foreach','dplyr','data.table', 'raster')
for(p in pkgs) {suppressPackageStartupMessages(require(p, quietly=TRUE, character.only=TRUE,warn.conflicts=FALSE))}
if(!"ID" %in% names(DataGroup)) stop("ID field does not exist")
if(class(DataGroup)!= "SpatialPointsDataFrame")     ## convert to SpatialPointsDataFrame and project
{
if(!"Latitude" %in% names(DataGroup)) stop("Latitude field does not exist")
if(!"Longitude" %in% names(DataGroup)) stop("Longitude field does not exist")
## set the minimum fields that are needed
CleanDataGroup <- DataGroup %>%
dplyr::select(.data$ID, .data$Latitude, .data$Longitude, .data$DateTime) %>%
arrange(.data$ID, .data$DateTime)
mid_point <- data.frame(geosphere::centroid(cbind(CleanDataGroup$Longitude, CleanDataGroup$Latitude)))
### PREVENT PROJECTION PROBLEMS FOR DATA SPANNING DATELINE
if (min(CleanDataGroup$Longitude) < -170 &  max(CleanDataGroup$Longitude) > 170) {
longs = ifelse(CleanDataGroup$Longitude < 0, CleanDataGroup$Longitude + 360, CleanDataGroup$Longitude)
mid_point$lon <- ifelse(median(longs) > 180, median(longs) - 360, median(longs))}
DataGroup.Wgs <- SpatialPoints(data.frame(CleanDataGroup$Longitude, CleanDataGroup$Latitude), proj4string=CRS("+proj=longlat + datum=wgs84"))
proj.UTM <- CRS(paste("+proj=laea +lon_0=", mid_point$lon, " +lat_0=", mid_point$lat, sep=""))
DataGroup.Projected <- spTransform(DataGroup.Wgs, CRS=proj.UTM )
TripCoords <- SpatialPointsDataFrame(DataGroup.Projected, data = CleanDataGroup)
TripCoords@data <- TripCoords@data %>% dplyr::select(.data$ID)
}else{  ## if data are already in a SpatialPointsDataFrame then check for projection
if(is.projected(DataGroup)){
TripCoords <- DataGroup
TripCoords@data <- TripCoords@data %>% dplyr::select(.data$ID)
}else{ ## project data to UTM if not projected
if(!"Latitude" %in% names(DataGroup)) stop("Latitude field does not exist")
if(!"Longitude" %in% names(DataGroup)) stop("Longitude field does not exist")
mid_point <- data.frame(geosphere::centroid(cbind(DataGroup@data$Longitude, DataGroup@data$Latitude)))
### PREVENT PROJECTION PROBLEMS FOR DATA SPANNING DATELINE
if (min(DataGroup@data$Longitude) < -170 &  max(DataGroup@data$Longitude) > 170) {
longs = ifelse(DataGroup@data$Longitude < 0, DataGroup@data$Longitude + 360,DataGroup@data$Longitude)
mid_point$lon<-ifelse(median(longs) > 180, median(longs)-360, median(longs))}
proj.UTM <- CRS(paste("+proj=laea +lon_0=", mid_point$lon, " +lat_0=", mid_point$lat, sep=""))
TripCoords <- sp::spTransform(DataGroup, CRS=proj.UTM)
TripCoords@data <- TripCoords@data %>% dplyr::select(ID)
}
}
UIDs <- unique(TripCoords$ID)
NIDs <- length(UIDs)
if(NIDs<50){Nloop <- seq(1, (NIDs - 1), 1)}
if(NIDs>=50 & NIDs<100){Nloop <- c(seq(1, 19, 1), seq(20, (NIDs - 1), 3))}
if(NIDs>=100){Nloop <- c(seq(1, 20, 1), seq(21, 49, 3), seq(50, (NIDs - 1), 6))}
DoubleLoop <- data.frame(SampleSize = rep(Nloop, each=Iteration), Iteration=rep(seq(1:Iteration), length(Nloop)))
LoopNr <- seq(1:dim(DoubleLoop)[1])
# Determine class of KDE, and convert to Raster
if(is.null(KDE)){
if(is.null(Res)) { Res <- 100 }
KDE.Surface <- estSpaceUse(DataGroup=TripCoords, Scale = Scale, Res = Res, UDLev = 50, polyOut=F)
KDEraster <- stack(lapply(KDE.Surface, function(x) raster::raster(x, values=T)))
} else if(class(KDE) == "list") {
KDE.Surface <- KDE$KDE.Surface
KDEraster <- stack(lapply(KDE.Surface, function(x) raster::raster(x, values=T)))
} else if(class(KDE) == "estUDm"){
KDE.Surface <- KDE
KDEraster <- stack(lapply(KDE, function(x) raster(as(x,"SpatialPixelsDataFrame"), values=T)))
# KDEraster <- raster::stack(KDE.Surface)
} else if(class(KDE) == "SpatialPixelsDataFrame") {
KDE.Surface <- KDE
KDEraster <- stack(KDE.Surface)
} else if(class(KDE) == "RasterStack") {
KDE.Surface <- KDE
}
###
Ncores <- 2
maxCores <- parallel::detectCores()
Ncores <- ifelse(Ncores == maxCores, Ncores - 1, Ncores) # ensure that at least one core is un-used
cl <- parallel::makeCluster(Ncores)
doParallel::registerDoParallel(cl)
# registerDoSEQ()  # sequential processing
Result <- data.frame()
Result <- foreach::foreach(LoopN = LoopNr, .combine = rbind, .packages = c("sp", "dplyr", "raster")) %dopar% {
N <- DoubleLoop$SampleSize[LoopN]
i <- DoubleLoop$Iteration[LoopN]
Output <- data.frame(SampleSize = N, InclusionMean = 0,Iteration=i)
RanNum <- sample(UIDs, N, replace=F)
NotSelected <- TripCoords[!TripCoords$ID %in% RanNum,]
SelectedTracks <- TripCoords[TripCoords$ID %in% RanNum,]
if(all(stringr::str_detect(names(KDEraster), pattern = "^X"))){
Selected <- KDEraster[[paste("X", RanNum, sep = "")]]
} else {
Selected <- KDEraster[[ RanNum ]]
}
KDEstack <- raster::stack(Selected)  # list of RasterLayers to RasterStack
# KDEstack <- Selected
if(avgMethod=="weighted"){
weights <- as.vector(unname(table(SelectedTracks$ID)))   # get number of points per ID
KDEcmbnd <- raster::weighted.mean(KDEstack, w=weights)   # weighted mean
} else if( avgMethod == "mean"){
KDEcmbnd <- raster::calc(KDEstack, mean)                 # arithmetic mean
}
### Calculating inclusion value, using Kernel surface ######
KDElev <- KDEcmbnd
pixArea <- res(KDElev)[1]
### original ##
df <- data.frame(UD = getValues(KDElev)) %>%
mutate(rowname = 1:length(getValues(KDElev))) %>%
mutate(usage = .data$UD * (pixArea^2)) %>%
arrange(desc(.data$usage)) %>%
mutate(cumulUD = cumsum(.data$usage)) %>%
mutate(INSIDE = ifelse(.data$cumulUD < 0.5, 1, NA)) %>%
arrange(.data$rowname) %>%
dplyr::select(.data$INSIDE)
KDElev[] <- df$INSIDE
# plot(KDElev)
Overlain_Raster <- raster::extract(KDElev, NotSelected)
Output$InclusionMean <- length(which(!is.na(Overlain_Raster)))/nrow(NotSelected)
return(Output)
}
## stop the cluster
on.exit(stopCluster(cl))
if(BootTable==T){
write.csv(Result,"bootout_temp.csv", row.names=F)
}
try(M1 <- stats::nls((Result$InclusionMean ~ (a*Result$SampleSize)/(1+b*Result$SampleSize)), data=Result, start=list(a=1,b=0.1)), silent = TRUE)
if ('M1' %in% ls()){       ### run this only if nls was successful
Asymptote <- (base::summary(M1)$coefficients[1] / summary(M1)$coefficients[2])
Result$pred <- stats::predict(M1)
## Calculate RepresentativeValue
RepresentativeValue <- Result %>%
group_by(SampleSize) %>%
summarise(out = max(pred) / ifelse(Asymptote < 0.45, 0.5, Asymptote)*100) %>%
dplyr::filter(out == max(.data$out)) %>%
mutate(type = ifelse(Asymptote < 0.45, 'asymptote_adj', 'asymptote')) %>%
mutate(asym = Asymptote)
if(Asymptote < 0.45) {
RepresentativeValue$asym_adj <- 0.5 }
## Plot
P2 <- Result %>%
group_by(.data$SampleSize) %>%
dplyr::summarise(
meanPred = mean(na.omit(.data$pred)),
sdInclude = sd(.data$InclusionMean))
yTemp <- c(P2$meanPred + 0.5 * P2$sdInclude, rev(P2$meanPred - 0.5 * P2$sdInclude))
xTemp <- c(P2$SampleSize, rev(P2$SampleSize))
# pdf("track2kba_repAssess_output.pdf", width=6, height=5)  ## avoids the plotting margins error
print(plot(InclusionMean ~ SampleSize,
data = Result, pch = 16, cex = 0.2, col="darkgray", ylim = c(0,1), xlim = c(0,max(unique(Result$SampleSize))), ylab = "Inclusion", xlab = "Sample Size"))
polygon(x = xTemp, y = yTemp, col = "gray93", border = F)
points(InclusionMean ~ SampleSize, data=Result, pch=16, cex=0.2, col="darkgray")
lines(P2, lty=1,lwd=2)
text(x=0, y=0.99, paste(round(RepresentativeValue$out, 2), "%", sep=""), cex=2, col="gray45", adj=0)
# dev.off()
}else{ ### if nls is unsuccessful then use mean output for largest sample size
RepresentativeValue <- Result %>%
dplyr::filter(SampleSize == max(.data$SampleSize)) %>%
group_by(.data$SampleSize) %>%
summarise(out = mean(.data$InclusionMean)) %>%
mutate(type = 'inclusion') %>%
mutate(asym = .data$out)
}
print(ifelse(exists("M1"),"nls (non linear regression) successful, asymptote estimated for bootstrap sample.",
"WARNING: nls (non linear regression) unsuccessful, likely due to 'singular gradient', which means there is no asymptote. Data may not be representative, output derived from mean inclusion value at highest sample size. Check bootstrap output csv file"))
return(as.data.frame(RepresentativeValue))
}
cores <- c(1, 2, 3, 4, 5, 10)
durations <- list()
for(i in 1:length(cores)){
cs <- cores[i]
print(cs)
before <- Sys.time()
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=5, Ncores = cs,  BootTable = F)
time <- Sys.time() - before
durations[[i]] <- time
}
durs <- cbind(cores, do.call(rbind, durations))
durs
?gc(0)
debug(repAssess)
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=2, BootTable = F, avgMethod="mean", Ncores = 1)
function(DataGroup, KDE=NULL, Iteration=50, Scale=NULL, Res=NULL, avgMethod = "mean", Ncores=1, BootTable=FALSE){
pkgs <- c('sp', 'geosphere', 'adehabitatHR','foreach','dplyr','data.table', 'raster')
for(p in pkgs) {suppressPackageStartupMessages(require(p, quietly=TRUE, character.only=TRUE,warn.conflicts=FALSE))}
if(!"ID" %in% names(DataGroup)) stop("ID field does not exist")
if(class(DataGroup)!= "SpatialPointsDataFrame")     ## convert to SpatialPointsDataFrame and project
{
if(!"Latitude" %in% names(DataGroup)) stop("Latitude field does not exist")
if(!"Longitude" %in% names(DataGroup)) stop("Longitude field does not exist")
## set the minimum fields that are needed
CleanDataGroup <- DataGroup %>%
dplyr::select(.data$ID, .data$Latitude, .data$Longitude, .data$DateTime) %>%
arrange(.data$ID, .data$DateTime)
mid_point <- data.frame(geosphere::centroid(cbind(CleanDataGroup$Longitude, CleanDataGroup$Latitude)))
### PREVENT PROJECTION PROBLEMS FOR DATA SPANNING DATELINE
if (min(CleanDataGroup$Longitude) < -170 &  max(CleanDataGroup$Longitude) > 170) {
longs = ifelse(CleanDataGroup$Longitude < 0, CleanDataGroup$Longitude + 360, CleanDataGroup$Longitude)
mid_point$lon <- ifelse(median(longs) > 180, median(longs) - 360, median(longs))}
DataGroup.Wgs <- SpatialPoints(data.frame(CleanDataGroup$Longitude, CleanDataGroup$Latitude), proj4string=CRS("+proj=longlat + datum=wgs84"))
proj.UTM <- CRS(paste("+proj=laea +lon_0=", mid_point$lon, " +lat_0=", mid_point$lat, sep=""))
DataGroup.Projected <- spTransform(DataGroup.Wgs, CRS=proj.UTM )
TripCoords <- SpatialPointsDataFrame(DataGroup.Projected, data = CleanDataGroup)
TripCoords@data <- TripCoords@data %>% dplyr::select(.data$ID)
}else{  ## if data are already in a SpatialPointsDataFrame then check for projection
if(is.projected(DataGroup)){
TripCoords <- DataGroup
TripCoords@data <- TripCoords@data %>% dplyr::select(.data$ID)
}else{ ## project data to UTM if not projected
if(!"Latitude" %in% names(DataGroup)) stop("Latitude field does not exist")
if(!"Longitude" %in% names(DataGroup)) stop("Longitude field does not exist")
mid_point <- data.frame(geosphere::centroid(cbind(DataGroup@data$Longitude, DataGroup@data$Latitude)))
### PREVENT PROJECTION PROBLEMS FOR DATA SPANNING DATELINE
if (min(DataGroup@data$Longitude) < -170 &  max(DataGroup@data$Longitude) > 170) {
longs = ifelse(DataGroup@data$Longitude < 0, DataGroup@data$Longitude + 360,DataGroup@data$Longitude)
mid_point$lon<-ifelse(median(longs) > 180, median(longs)-360, median(longs))}
proj.UTM <- CRS(paste("+proj=laea +lon_0=", mid_point$lon, " +lat_0=", mid_point$lat, sep=""))
TripCoords <- sp::spTransform(DataGroup, CRS=proj.UTM)
TripCoords@data <- TripCoords@data %>% dplyr::select(ID)
}
}
UIDs <- unique(TripCoords$ID)
NIDs <- length(UIDs)
if(NIDs<50){Nloop <- seq(1, (NIDs - 1), 1)}
if(NIDs>=50 & NIDs<100){Nloop <- c(seq(1, 19, 1), seq(20, (NIDs - 1), 3))}
if(NIDs>=100){Nloop <- c(seq(1, 20, 1), seq(21, 49, 3), seq(50, (NIDs - 1), 6))}
DoubleLoop <- data.frame(SampleSize = rep(Nloop, each=Iteration), Iteration=rep(seq(1:Iteration), length(Nloop)))
LoopNr <- seq(1:dim(DoubleLoop)[1])
# Determine class of KDE, and convert to Raster
if(is.null(KDE)){
if(is.null(Res)) { Res <- 100 }
KDE.Surface <- estSpaceUse(DataGroup=TripCoords, Scale = Scale, Res = Res, UDLev = 50, polyOut=F)
KDEraster <- stack(lapply(KDE.Surface, function(x) raster::raster(x, values=T)))
} else if(class(KDE) == "list") {
KDE.Surface <- KDE$KDE.Surface
KDEraster <- stack(lapply(KDE.Surface, function(x) raster::raster(x, values=T)))
} else if(class(KDE) == "estUDm"){
KDE.Surface <- KDE
KDEraster <- stack(lapply(KDE, function(x) raster(as(x,"SpatialPixelsDataFrame"), values=T)))
# KDEraster <- raster::stack(KDE.Surface)
} else if(class(KDE) == "SpatialPixelsDataFrame") {
KDE.Surface <- KDE
KDEraster <- stack(KDE.Surface)
} else if(class(KDE) == "RasterStack") {
KDE.Surface <- KDE
}
###
Ncores <- 2
maxCores <- parallel::detectCores()
Ncores <- ifelse(Ncores == maxCores, Ncores - 1, Ncores) # ensure that at least one core is un-used
cl <- parallel::makeCluster(Ncores)
doParallel::registerDoParallel(cl)
# registerDoSEQ()  # sequential processing
Result <- data.frame()
Result <- foreach::foreach(LoopN = LoopNr, .combine = rbind, .packages = c("sp", "dplyr", "raster")) %dopar% {
N <- DoubleLoop$SampleSize[LoopN]
i <- DoubleLoop$Iteration[LoopN]
Output <- data.frame(SampleSize = N, InclusionMean = 0,Iteration=i)
RanNum <- sample(UIDs, N, replace=F)
NotSelected <- TripCoords[!TripCoords$ID %in% RanNum,]
SelectedTracks <- TripCoords[TripCoords$ID %in% RanNum,]
if(all(stringr::str_detect(names(KDEraster), pattern = "^X"))){
Selected <- KDEraster[[paste("X", RanNum, sep = "")]]
} else {
Selected <- KDEraster[[ RanNum ]]
}
KDEstack <- raster::stack(Selected)  # list of RasterLayers to RasterStack
# KDEstack <- Selected
if(avgMethod=="weighted"){
weights <- as.vector(unname(table(SelectedTracks$ID)))   # get number of points per ID
KDEcmbnd <- raster::weighted.mean(KDEstack, w=weights)   # weighted mean
} else if( avgMethod == "mean"){
KDEcmbnd <- raster::calc(KDEstack, mean)                 # arithmetic mean
}
### Calculating inclusion value, using Kernel surface ######
KDElev <- KDEcmbnd
pixArea <- res(KDElev)[1]
### original ##
df <- data.frame(UD = getValues(KDElev)) %>%
mutate(rowname = 1:length(getValues(KDElev))) %>%
mutate(usage = .data$UD * (pixArea^2)) %>%
arrange(desc(.data$usage)) %>%
mutate(cumulUD = cumsum(.data$usage)) %>%
mutate(INSIDE = ifelse(.data$cumulUD < 0.5, 1, NA)) %>%
arrange(.data$rowname) %>%
dplyr::select(.data$INSIDE)
KDElev[] <- df$INSIDE
# plot(KDElev)
Overlain_Raster <- raster::extract(KDElev, NotSelected)
Output$InclusionMean <- length(which(!is.na(Overlain_Raster)))/nrow(NotSelected)
return(Output)
}
## stop the cluster
on.exit(stopCluster(cl))
if(BootTable==T){
write.csv(Result,"bootout_temp.csv", row.names=F)
}
try(M1 <- stats::nls((Result$InclusionMean ~ (a*Result$SampleSize)/(1+b*Result$SampleSize)), data=Result, start=list(a=1,b=0.1)), silent = TRUE)
if ('M1' %in% ls()){       ### run this only if nls was successful
Asymptote <- (base::summary(M1)$coefficients[1] / summary(M1)$coefficients[2])
Result$pred <- stats::predict(M1)
## Calculate RepresentativeValue
RepresentativeValue <- Result %>%
group_by(SampleSize) %>%
summarise(out = max(pred) / ifelse(Asymptote < 0.45, 0.5, Asymptote)*100) %>%
dplyr::filter(out == max(.data$out)) %>%
mutate(type = ifelse(Asymptote < 0.45, 'asymptote_adj', 'asymptote')) %>%
mutate(asym = Asymptote)
if(Asymptote < 0.45) {
RepresentativeValue$asym_adj <- 0.5 }
## Plot
P2 <- Result %>%
group_by(.data$SampleSize) %>%
dplyr::summarise(
meanPred = mean(na.omit(.data$pred)),
sdInclude = sd(.data$InclusionMean))
yTemp <- c(P2$meanPred + 0.5 * P2$sdInclude, rev(P2$meanPred - 0.5 * P2$sdInclude))
xTemp <- c(P2$SampleSize, rev(P2$SampleSize))
# pdf("track2kba_repAssess_output.pdf", width=6, height=5)  ## avoids the plotting margins error
print(plot(InclusionMean ~ SampleSize,
data = Result, pch = 16, cex = 0.2, col="darkgray", ylim = c(0,1), xlim = c(0,max(unique(Result$SampleSize))), ylab = "Inclusion", xlab = "Sample Size"))
polygon(x = xTemp, y = yTemp, col = "gray93", border = F)
points(InclusionMean ~ SampleSize, data=Result, pch=16, cex=0.2, col="darkgray")
lines(P2, lty=1,lwd=2)
text(x=0, y=0.99, paste(round(RepresentativeValue$out, 2), "%", sep=""), cex=2, col="gray45", adj=0)
# dev.off()
}else{ ### if nls is unsuccessful then use mean output for largest sample size
RepresentativeValue <- Result %>%
dplyr::filter(SampleSize == max(.data$SampleSize)) %>%
group_by(.data$SampleSize) %>%
summarise(out = mean(.data$InclusionMean)) %>%
mutate(type = 'inclusion') %>%
mutate(asym = .data$out)
}
print(ifelse(exists("M1"),"nls (non linear regression) successful, asymptote estimated for bootstrap sample.",
"WARNING: nls (non linear regression) unsuccessful, likely due to 'singular gradient', which means there is no asymptote. Data may not be representative, output derived from mean inclusion value at highest sample size. Check bootstrap output csv file"))
return(as.data.frame(RepresentativeValue))
}
KDEraster <- stack(lapply(KDE, function(x) raster(as(x,"SpatialPixelsDataFrame"), values=T)))
Ncores <- 2
maxCores <- parallel::detectCores()
Ncores <- ifelse(Ncores == maxCores, Ncores - 1, Ncores) # ensure that at least one core is un-used
cl <- parallel::makeCluster(Ncores)
doParallel::registerDoParallel(cl)
LoopNr
rep(Nloop, each=Iteration)
if(NIDs<50){Nloop <- seq(1, (NIDs - 1), 1)}
Nloop <- seq(1, (NIDs - 1), 1)
Nloop
Iteration
length(UIDs)
DoubleLoop
LoopNr <- seq(1:dim(DoubleLoop)[1])
LoopNr
Nloop
list(SampleSize = rep(Nloop, each=Iteration), Iteration=rep(seq(1:Iteration), length(Nloop)))
?list
list(2)
vector("list", Iteration)
itsList <- vector("list", Iteration)
lapply(itsList, function(x)){ rep(Nloop) }
lapply(itsList, function(x) { rep(Nloop) })
lapply(itsList, function(x) { data.frame(SampleSize = rep(Nloop, each=Iteration), Iteration=rep(seq(1:Iteration), length(Nloop)))
} )
data.frame(SampleSize = rep(Nloop))
seq(1:Iteration)
lapply(itsList, function(x) { data.frame(SampleSize = rep(Nloop), Iteration=rep( length(Nloop))) } )
seq(1:Iteration)
lapply(itsList, function(x, i) { data.frame(SampleSize = rep(Nloop), Iteration=rep(seq(1:Iteration)[[i]], length(Nloop))) } )
seq(1:Iteration)
lapply(itsList, function(x, i) { data.frame(SampleSize = rep(Nloop), Iteration=rep(seq(1:Iteration)[i], length(Nloop))) } )
lapply(itsList, function(x) { data.frame(SampleSize = rep(Nloop), Iteration=rep(seq(1:Iteration)[ names[[x]] ], length(Nloop))) } )
lapply(itsList, function(x) { names(itsList) }
lapply(itsList, function(x) { names(itsList) } )
1:length(itsList)
lapply(1:length(itsList), function(x) { itsList[[x]] } )
lapply(1:length(itsList), function(x) { itsList[x] } )
lapply(1:length(itsList), function(x) { data.frame(SampleSize = rep(Nloop), Iteration=rep(seq(1:Iteration)[x], length(Nloop))) } )
loopList <- lapply(1:length(itsList), function(x) { data.frame(SampleSize = rep(Nloop), Iteration=rep(seq(1:Iteration)[x], length(Nloop))) } )
1:length(itsList)
data.frame(SampleSize = rep(Nloop), Iteration=rep(seq(1:Iteration)[x], length(Nloop)), InclusionMean = rep(NA))
loopList <- lapply(1:length(itsList), function(x) {
data.frame(SampleSize = rep(Nloop), Iteration=rep(seq(1:Iteration)[x], length(Nloop)), InclusionMean = rep(NA))
}
)
loopList
N=1
RanNum <- sample(UIDs, N, replace=F)
RanNum
N=3
RanNum <- sample(UIDs, N, replace=F)
RanNum
