Result$pred <- stats::predict(M1)
## Calculate RepresentativeValue
RepresentativeValue <- Result %>%
group_by(SampleSize) %>%
summarise(
out       = max(pred) / ifelse(Asymptote < (tAsymp - .05), tAsymp, Asymptote)*100
) %>%
dplyr::filter(out == max(.data$out)) %>%
mutate(type = ifelse(Asymptote < (tAsymp - .05), 'asymptote_adj', 'asymptote')) %>%
mutate(asym = Asymptote)
if(Asymptote < (tAsymp - .05)) {
RepresentativeValue$asym_adj <- tAsymp
AsymforCalc <- tAsymp
} else { AsymforCalc <- Asymptote }
# Calculate minimum and fully representative sample sizes, and convert inclusions into rep. estimates
minRep <- 0.7*Asymptote
fullRep <- 0.99*Asymptote
RepresentativeValue$minRep <- ceiling(minRep / (a - (minRep*b)))
RepresentativeValue$fullRep <- ceiling(fullRep / (a - (fullRep*b)))
Result <- Result %>% mutate(
rep_est = pred / ifelse(AsymforCalc < (tAsymp - .05), tAsymp, AsymforCalc)*100,
is_rep  = ifelse(rep_est >= 70, TRUE, FALSE)
)
## Plot
P2 <- Result %>%
group_by(.data$SampleSize) %>%
dplyr::summarise(
meanPred = mean(na.omit(.data$pred)),
sdInclude = sd(.data$InclusionMean))
yTemp <- c(P2$meanPred + AsymforCalc * P2$sdInclude, rev(P2$meanPred - AsymforCalc * P2$sdInclude))
xTemp <- c(P2$SampleSize, rev(P2$SampleSize))
# pdf("track2kba_repAssess_output.pdf", width=6, height=5)  ## avoids the plotting margins error
print(plot(InclusionMean ~ SampleSize,
data = Result, pch = 16, cex = 0.2, col="darkgray", ylim = c(0,1), xlim = c(0,max(unique(Result$SampleSize))), ylab = "Inclusion", xlab = "Sample Size"))
polygon(x = xTemp, y = yTemp, col = "gray93", border = F)
points(InclusionMean ~ SampleSize, data=Result, pch=16, cex=0.2, col="darkgray")
lines(P2, lty=1,lwd=2)
text(x=0, y=0.99, paste(round(RepresentativeValue$out, 2), "%", sep=""), cex=2, col="gray45", adj=0)
# dev.off()
}else{ ### if nls is unsuccessful then use mean output for largest sample size
RepresentativeValue <- Result %>%
dplyr::filter(SampleSize == max(.data$SampleSize)) %>%
group_by(.data$SampleSize) %>%
summarise(
out = mean(.data$InclusionMean)
) %>%
mutate(type = 'inclusion') %>%
mutate(asym = .data$out)
}
if(BootTable==T){
write.csv(Result,"bootout_temp.csv", row.names=F)
}
print(ifelse(exists("M1"),"nls (non linear regression) successful, asymptote estimated for bootstrap sample.",
"WARNING: nls (non linear regression) unsuccessful, likely due to 'singular gradient', which means there is no asymptote. Data may not be representative, output derived from mean inclusion value at highest sample size. Check bootstrap output csv file"))
return(as.data.frame(RepresentativeValue))
}
minRep <- 0.7*AsymforCalc
fullRep <- 0.99*AsymforCalc
RepresentativeValue$minRep <- ceiling(minRep / (a - (minRep*b)))
RepresentativeValue$fullRep <- ceiling(fullRep / (a - (fullRep*b)))
Result <- Result %>% mutate(
rep_est = pred / ifelse(AsymforCalc < (tAsymp - .05), tAsymp, AsymforCalc)*100,
is_rep  = ifelse(rep_est >= 70, TRUE, FALSE)
)
Result
RepresentativeValue
minRep <- 0.7*Asymptote
fullRep <- 0.99*Asymptote
RepresentativeValue$minRep <- ceiling(minRep / (a - (minRep*b)))
RepresentativeValue$fullRep <- ceiling(fullRep / (a - (fullRep*b)))
Result <- Result %>% mutate(
rep_est = pred / ifelse(AsymforCalc < (tAsymp - .05), tAsymp, AsymforCalc)*100,
is_rep  = ifelse(rep_est >= 70, TRUE, FALSE)
)
RepresentativeValue
max(pred) / Asymptote
RepresentativeValue <- Result %>%
group_by(SampleSize) %>%
summarise(
out       = max(pred) / Asymptote*100
) %>%
dplyr::filter(out == max(.data$out)) %>%
mutate(type = ifelse(Asymptote < (tAsymp - .05), 'asymptote_adj', 'asymptote')) %>%
mutate(asym = Asymptote)
RepresentativeValue
RepresentativeValue <- Result %>%
group_by(SampleSize) %>%
summarise(
out       = max(pred) / ifelse(Asymptote < (tAsymp - .05), tAsymp, Asymptote)*100
) %>%
dplyr::filter(out == max(.data$out)) %>%
mutate(type = ifelse(Asymptote < (tAsymp - .05), 'asymptote_adj', 'asymptote')) %>%
mutate(asym = Asymptote)
minRep <- 0.7*Asymptote
fullRep <- 0.99*Asymptote
RepresentativeValue$minRep <- ceiling(minRep / (a - (minRep*b)))
RepresentativeValue$fullRep <- ceiling(fullRep / (a - (fullRep*b)))
RepresentativeValue
P2 <- Result %>%
group_by(.data$SampleSize) %>%
dplyr::summarise(
meanPred = mean(na.omit(.data$pred)),
sdInclude = sd(.data$InclusionMean))
yTemp <- c(P2$meanPred + AsymforCalc * P2$sdInclude, rev(P2$meanPred - AsymforCalc * P2$sdInclude))
xTemp <- c(P2$SampleSize, rev(P2$SampleSize))
yTemp
AsymforCalc
AsymforCalc <- Asymptote
yTemp <- c(P2$meanPred + AsymforCalc * P2$sdInclude, rev(P2$meanPred - AsymforCalc * P2$sdInclude))
print(plot(InclusionMean ~ SampleSize,
data = Result, pch = 16, cex = 0.2, col="darkgray", ylim = c(0,1), xlim = c(0,max(unique(Result$SampleSize))), ylab = "Inclusion", xlab = "Sample Size"))
polygon(x = xTemp, y = yTemp, col = "gray93", border = F)
points(InclusionMean ~ SampleSize, data=Result, pch=16, cex=0.2, col="darkgray")
lines(P2, lty=1,lwd=2)
text(x=0, y=0.99, paste(round(RepresentativeValue$out, 2), "%", sep=""), cex=2, col="gray45", adj=0)
P2 <- Result %>%
group_by(.data$SampleSize) %>%
dplyr::summarise(
meanPred = mean(na.omit(.data$pred)),
sdInclude = sd(.data$InclusionMean))
yTemp <- c(P2$meanPred + AsymforCalc * P2$sdInclude, rev(P2$meanPred - AsymforCalc * P2$sdInclude))
xTemp <- c(P2$SampleSize, rev(P2$SampleSize))
# pdf("track2kba_repAssess_output.pdf", width=6, height=5)  ## avoids the plotting margins error
print(plot(InclusionMean ~ SampleSize,
data = Result, pch = 16, cex = 0.2, col="darkgray", ylim = c(0,1), xlim = c(0,max(unique(Result$SampleSize))), ylab = "Inclusion", xlab = "Sample Size"))
polygon(x = xTemp, y = yTemp, col = "gray93", border = F)
points(InclusionMean ~ SampleSize, data=Result, pch=16, cex=0.2, col="darkgray")
lines(P2, lty=1,lwd=2)
text(x=0, y=0.99, paste(round(RepresentativeValue$out, 2), "%", sep=""), cex=2, col="gray45", adj=0)
# dev.off()
P2
c(P2$SampleSize, rev(P2$SampleSize))
polygon(x = xTemp, y = yTemp, col = "gray93", border = F)
P2$meanPred + AsymforCalc
P2$meanPred
P2$meanPred + AsymforCalc * P2$sdInclude
minRep <- 0.7*Asymptote
fullRep <- 0.99*Asymptote
RepresentativeValue$minRep <- ceiling(minRep / (a - (minRep*b)))
RepresentativeValue$fullRep <- ceiling(fullRep / (a - (fullRep*b)))
Result <- Result %>% mutate(
rep_est = pred / Asymptote*100,
is_rep  = ifelse(rep_est >= 70, TRUE, FALSE)
)
## Plot
P2 <- Result %>%
group_by(.data$SampleSize) %>%
dplyr::summarise(
meanPred = mean(na.omit(.data$pred)),
sdInclude = sd(.data$InclusionMean))
yTemp <- c(P2$meanPred + Asymptote * P2$sdInclude, rev(P2$meanPred - Asymptote * P2$sdInclude))
xTemp <- c(P2$SampleSize, rev(P2$SampleSize))
# pdf("track2kba_repAssess_output.pdf", width=6, height=5)  ## avoids the plotting margins error
print(plot(InclusionMean ~ SampleSize,
data = Result, pch = 16, cex = 0.2, col="darkgray", ylim = c(0,1), xlim = c(0,max(unique(Result$SampleSize))), ylab = "Inclusion", xlab = "Sample Size"))
polygon(x = xTemp, y = yTemp, col = "gray93", border = F)
points(InclusionMean ~ SampleSize, data=Result, pch=16, cex=0.2, col="darkgray")
lines(P2, lty=1,lwd=2)
text(x=0, y=0.99, paste(round(RepresentativeValue$out, 2), "%", sep=""), cex=2, col="gray45", adj=0)
# dev.off()
P2[,2]
0.5*P2[,3]
P2[,3]
Asymptote * P2$sdInclude
P2$sdInclude
Asymptote
P2$meanPred + Asymptote * P2$sdInclude
Asymptote
P2[,2] - 0.5*P2[,3]
P2
repAssess <- function(DataGroup, KDE=NULL, Iteration=50, Scale=NULL, Res=NULL, UDLev=50, avgMethod = "mean", Ncores=1, BootTable=FALSE){
pkgs <- c('sp', 'geosphere', 'adehabitatHR','foreach','dplyr','data.table', 'raster')
for(p in pkgs) {suppressPackageStartupMessages(require(p, quietly=TRUE, character.only=TRUE,warn.conflicts=FALSE))}
if(!"ID" %in% names(DataGroup)) stop("ID field does not exist")
if(class(DataGroup)!= "SpatialPointsDataFrame")     ## convert to SpatialPointsDataFrame and project
{
if(!"Latitude" %in% names(DataGroup)) stop("Latitude field does not exist")
if(!"Longitude" %in% names(DataGroup)) stop("Longitude field does not exist")
## set the minimum fields that are needed
CleanDataGroup <- DataGroup %>%
dplyr::select(.data$ID, .data$Latitude, .data$Longitude, .data$DateTime) %>%
arrange(.data$ID, .data$DateTime)
mid_point <- data.frame(geosphere::centroid(cbind(CleanDataGroup$Longitude, CleanDataGroup$Latitude)))
### PREVENT PROJECTION PROBLEMS FOR DATA SPANNING DATELINE
if (min(CleanDataGroup$Longitude) < -170 &  max(CleanDataGroup$Longitude) > 170) {
longs = ifelse(CleanDataGroup$Longitude < 0, CleanDataGroup$Longitude + 360, CleanDataGroup$Longitude)
mid_point$lon <- ifelse(median(longs) > 180, median(longs) - 360, median(longs))}
DataGroup.Wgs <- SpatialPoints(data.frame(CleanDataGroup$Longitude, CleanDataGroup$Latitude), proj4string=CRS("+proj=longlat + datum=wgs84"))
proj.UTM <- CRS(paste("+proj=laea +lon_0=", mid_point$lon, " +lat_0=", mid_point$lat, sep=""))
DataGroup.Projected <- spTransform(DataGroup.Wgs, CRS=proj.UTM )
TripCoords <- SpatialPointsDataFrame(DataGroup.Projected, data = CleanDataGroup)
TripCoords@data <- TripCoords@data %>% dplyr::select(.data$ID)
}else{  ## if data are already in a SpatialPointsDataFrame then check for projection
if(is.projected(DataGroup)){
TripCoords <- DataGroup
TripCoords@data <- TripCoords@data %>% dplyr::select(.data$ID)
}else{ ## project data to UTM if not projected
if(!"Latitude" %in% names(DataGroup)) stop("Latitude field does not exist")
if(!"Longitude" %in% names(DataGroup)) stop("Longitude field does not exist")
mid_point <- data.frame(geosphere::centroid(cbind(DataGroup@data$Longitude, DataGroup@data$Latitude)))
### PREVENT PROJECTION PROBLEMS FOR DATA SPANNING DATELINE
if (min(DataGroup@data$Longitude) < -170 &  max(DataGroup@data$Longitude) > 170) {
longs = ifelse(DataGroup@data$Longitude < 0, DataGroup@data$Longitude + 360,DataGroup@data$Longitude)
mid_point$lon<-ifelse(median(longs) > 180, median(longs)-360, median(longs))}
proj.UTM <- CRS(paste("+proj=laea +lon_0=", mid_point$lon, " +lat_0=", mid_point$lat, sep=""))
TripCoords <- sp::spTransform(DataGroup, CRS=proj.UTM)
TripCoords@data <- TripCoords@data %>% dplyr::select(ID)
}
}
UIDs <- unique(TripCoords$ID)
NIDs <- length(UIDs)
if(NIDs<50){Nloop <- seq(1, (NIDs - 1), 1)}
if(NIDs>=50 & NIDs<100){Nloop <- c(seq(1, 19, 1), seq(20, (NIDs - 1), 3))}
if(NIDs>=100){Nloop <- c(seq(1, 20, 1), seq(21, 49, 3), seq(50, (NIDs - 1), 6))}
DoubleLoop <- data.frame(SampleSize = rep(Nloop, each=Iteration), Iteration=rep(seq(1:Iteration), length(Nloop)))
LoopNr <- seq(1:dim(DoubleLoop)[1])
# Determine class of KDE, and convert to Raster
if(is.null(KDE)){
if(is.null(Res)) { Res <- 100 }
KDE.Surface <- estSpaceUse(DataGroup=TripCoords, Scale = Scale, Res = Res, UDLev = UDLev, polyOut=F)
KDEraster <- stack(lapply(KDE.Surface, function(x) raster::raster(x, values=T)))
} else if(class(KDE) == "list") {
KDE.Surface <- KDE$KDE.Surface
KDEraster <- stack(lapply(KDE.Surface, function(x) raster::raster(x, values=T)))
} else if(class(KDE) == "estUDm"){
KDE.Surface <- KDE
KDEraster <- stack(lapply(KDE, function(x) raster(as(x,"SpatialPixelsDataFrame"), values=T)))
# KDEraster <- raster::stack(KDE.Surface)
} else if(class(KDE) == "SpatialPixelsDataFrame") {
KDE.Surface <- KDE
KDEraster <- stack(KDE.Surface)
} else if(class(KDE) == "RasterStack") {
KDE.Surface <- KDE
}
###
#Ncores <- 7
maxCores <- parallel::detectCores()
Ncores <- ifelse(Ncores == maxCores, Ncores - 1, Ncores) # ensure that at least one core is un-used
cl <- parallel::makeCluster(Ncores)
doParallel::registerDoParallel(cl)
# registerDoSEQ()  # sequential processing
Result <- data.frame()
Result <- foreach::foreach(LoopN = LoopNr, .combine = rbind, .packages = c("sp", "dplyr", "raster")) %dopar% {
N <- DoubleLoop$SampleSize[LoopN]
i <- DoubleLoop$Iteration[LoopN]
Output <- data.frame(SampleSize = N, InclusionMean = 0,Iteration=i)
RanNum <- sample(UIDs, N, replace=F)
NotSelected <- TripCoords[!TripCoords$ID %in% RanNum,]
SelectedTracks <- TripCoords[TripCoords$ID %in% RanNum,]
if(all(stringr::str_detect(names(KDEraster), pattern = "^X"))){
Selected <- KDEraster[[paste("X", RanNum, sep = "")]]
} else {
Selected <- KDEraster[[ RanNum ]]
}
KDEstack <- raster::stack(Selected)  # list of RasterLayers to RasterStack
# KDEstack <- Selected
if(avgMethod=="weighted"){
weights <- as.vector(unname(table(SelectedTracks$ID)))   # get number of points per ID
KDEcmbnd <- raster::weighted.mean(KDEstack, w=weights)   # weighted mean
} else if( avgMethod == "mean"){
KDEcmbnd <- raster::calc(KDEstack, mean)                 # arithmetic mean
}
### Calculating inclusion value, using Kernel surface ######
KDElev <- KDEcmbnd
pixArea <- res(KDElev)[1]
### original ##
df <- data.frame(UD = getValues(KDElev)) %>%
mutate(rowname = 1:length(getValues(KDElev))) %>%
mutate(usage = .data$UD * (pixArea^2)) %>%
arrange(desc(.data$usage)) %>%
mutate(cumulUD = cumsum(.data$usage)) %>%
mutate(INSIDE = ifelse(.data$cumulUD < (UDLev/100), 1, NA)) %>%
arrange(.data$rowname) %>%
dplyr::select(.data$INSIDE)
KDElev[] <- df$INSIDE
# plot(KDElev)
Overlain_Raster <- raster::extract(KDElev, NotSelected)
Output$InclusionMean <- length(which(!is.na(Overlain_Raster)))/nrow(NotSelected)
return(Output)
}
## stop the cluster
on.exit(parallel::stopCluster(cl))
try(M1 <- stats::nls((Result$InclusionMean ~ (a*Result$SampleSize)/(1+b*Result$SampleSize)), data=Result, start=list(a=1,b=0.1)), silent = TRUE)
if ('M1' %in% ls()){       ### run this only if nls was successful
a <- base::summary(M1)$coefficients[1]
b <- base::summary(M1)$coefficients[2]
tAsymp <- (UDLev/100)
Asymptote <- (a / b)
Result$pred <- stats::predict(M1)
## Calculate RepresentativeValue
RepresentativeValue <- Result %>%
group_by(SampleSize) %>%
summarise(
out       = max(pred) / Asymptote*100
) %>%
dplyr::filter(out == max(.data$out)) %>%
mutate(
est_asym = Asymptote,
tar_asym = (UDLev/100)
)
if(Asymptote < (tAsymp - .05)) {
RepresentativeValue$asym_adj <- tAsymp
AsymforCalc <- tAsymp
} else { AsymforCalc <- Asymptote }
# Calculate minimum and fully representative sample sizes, and convert inclusions into rep. estimates
minRep <- 0.7*Asymptote
fullRep <- 0.99*Asymptote
RepresentativeValue$minRep <- ceiling(minRep / (a - (minRep*b)))
RepresentativeValue$fullRep <- ceiling(fullRep / (a - (fullRep*b)))
Result <- Result %>% mutate(
rep_est = pred / Asymptote*100,
is_rep  = ifelse(rep_est >= 70, TRUE, FALSE)
)
## Plot
P2 <- Result %>%
group_by(.data$SampleSize) %>%
dplyr::summarise(
meanPred = mean(na.omit(.data$pred)),
sdInclude = sd(.data$InclusionMean))
yTemp <- c(P2$meanPred + Asymptote * P2$sdInclude, rev(P2$meanPred - Asymptote * P2$sdInclude))
xTemp <- c(P2$SampleSize, rev(P2$SampleSize))
# pdf("track2kba_repAssess_output.pdf", width=6, height=5)  ## avoids the plotting margins error
print(plot(InclusionMean ~ SampleSize,
data = Result, pch = 16, cex = 0.2, col="darkgray", ylim = c(0,1), xlim = c(0,max(unique(Result$SampleSize))), ylab = "Inclusion", xlab = "Sample Size"))
polygon(x = xTemp, y = yTemp, col = "gray93", border = F)
points(InclusionMean ~ SampleSize, data=Result, pch=16, cex=0.2, col="darkgray")
lines(P2, lty=1,lwd=2)
text(x=0, y=0.99, paste(round(RepresentativeValue$out, 2), "%", sep=""), cex=2, col="gray45", adj=0)
# dev.off()
}else{ ### if nls is unsuccessful then use mean output for largest sample size
RepresentativeValue <- Result %>%
dplyr::filter(SampleSize == max(.data$SampleSize)) %>%
group_by(.data$SampleSize) %>%
summarise(
out = mean(.data$InclusionMean)
) %>%
mutate(type = 'inclusion') %>%
mutate(asym = .data$out)
}
if(BootTable==T){
write.csv(Result,"bootout_temp.csv", row.names=F)
}
print(ifelse(exists("M1"),"nls (non linear regression) successful, asymptote estimated for bootstrap sample.",
"WARNING: nls (non linear regression) unsuccessful, likely due to 'singular gradient', which means there is no asymptote. Data may not be representative, output derived from mean inclusion value at highest sample size. Check bootstrap output csv file"))
return(as.data.frame(RepresentativeValue))
}
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=10, UDLev=95, avgMethod="mean", Ncores = 5)
repr
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=10, UDLev=50, avgMethod="mean", Ncores = 5)
repr
KDE.Surface <- estSpaceUse(DataGroup=Trips, Scale = HVALS$mag, UDLev = 95, polyOut=T, plotIt = F)
class(KDE.Surface$KDE.Surface)
KDE.Surface
KDE.Surface <- estSpaceUse(DataGroup=Trips, Scale = HVALS$mag, UDLev = 95, Res=0.5 polyOut=T, plotIt = F)
KDE.Surface <- estSpaceUse(DataGroup=Trips, Scale = HVALS$mag, UDLev = 95, Res=0.5, polyOut=T, plotIt = F)
HVALS$mag
debug(estSpaceUse)
KDE.Surface <- estSpaceUse(DataGroup=Trips, Scale = HVALS$mag, UDLev = 95, Res=0.5, polyOut=T, plotIt = F)
### specify sequence of grid cells and combine to SpatialPixels
xrange <- seq(minX,maxX, by = Res*1000) #diff(range(coordinates(TripCoords)[,1]))/Res)   ### if Res should be provided in km we need to change this
yrange <- seq(minY,maxY, by = Res*1000) #diff(range(coordinates(TripCoords)[,2]))/Res)   ### if Res should be provided in km we need to change this
grid.locs <- expand.grid(x=xrange,y=yrange)
INPUTgrid <- SpatialPixels(SpatialPoints(grid.locs), proj4string=proj4string(TripCoords))
INPUTgrid
minX
min(coordinates(TripCoords)[,1])
KDE.Surface <- adehabitatHR::kernelUD(TripCoords, h=(Scale * 1000), grid=INPUTgrid, same4all=F)
KDE.Surface
plot(KDE.Surface)
image(KDE.Surface)
KDE.Sp <- adehabitatHR::getverticeshr(KDE.Surface, percent = UDLev,unin = "m", unout = "km2")
Scale*2000
Scale
Scale/0.1228
xrange
grid.locs <- expand.grid(x=xrange,y=yrange)
grid.locs
yrange <- seq(minY,maxY, by = Res*1000) #diff(range(coordinates(TripCoords)[,2]))/Res)   ### if Res should be provided in km we need to change this
yrange
yrange <- seq(minY,maxY, by = Res*1000) #diff(range(coordinates(TripCoords)[,2]))/Res)   ### if Res should be provided in km we need to change this
grid.locs <- expand.grid(x=xrange,y=yrange)
grid.locs
yrange
xrange
expand.grid(x=xrange,y=yrange)
sp::spDists(minX, maxX)
?spDists
min(coordinates(TripCoords)[,1])
?kernelUD
extent(TripCoords)
kernelUD
range(coordinates(TripCoords[,1]))
diff(range(coordinates(TripCoords[,1])))
(diff(range(coordinates(TripCoords[,1])))*0.1)
(diff(range(coordinates(TripCoords[,1])))*0.01)
pmax((diff(range(coordinates(TripCoords[,1])))*0.01), Scale*2000)
(diff(range(coordinates(TripCoords[,1])))*0.01)
?pmax
extendX <- max(diff(range(coordinates(TripCoords[,1])))*0.01), Scale*2000)
minX <- min(coordinates(TripCoords)[,1]) - extendX
maxX <- max(coordinates(TripCoords)[,1]) + extendX
minY <- min(coordinates(TripCoords)[,2]) - extendY
maxY <- max(coordinates(TripCoords)[,2]) + extendY
# minX <- min(coordinates(TripCoords)[,1]) - Scale*2000
# maxX <- max(coordinates(TripCoords)[,1]) + Scale*2000
# minY <- min(coordinates(TripCoords)[,2]) - Scale*2000
# maxY <- max(coordinates(TripCoords)[,2]) + Scale*2000
### if users do not provide a resolution, then split data into ~500 cells
if( is.null(Res) ){ Res <- ( max(abs(minX-maxX)/500, abs( minY-maxY )/500) )/1000
warning(sprintf("No grid resolution ('Res') was specified, or the specified resolution was >99 km and therefore ignored.
Space use was calculated on a 500-cell grid, with cells of %s square km", round(Res,3)),immediate. = TRUE)}
### specify sequence of grid cells and combine to SpatialPixels
xrange <- seq(minX,maxX, by = Res*1000) #diff(range(coordinates(TripCoords)[,1]))/Res)   ### if Res should be provided in km we need to change this
yrange <- seq(minY,maxY, by = Res*1000) #diff(range(coordinates(TripCoords)[,2]))/Res)   ### if Res should be provided in km we need to change this
grid.locs <- expand.grid(x=xrange,y=yrange)
INPUTgrid <- SpatialPixels(SpatialPoints(grid.locs), proj4string=proj4string(TripCoords))
#  plot(INPUTgrid)
KDE.Sp <- adehabitatHR::getverticeshr(KDE.Surface, percent = UDLev,unin = "m", unout = "km2")
KDE.Surface <- adehabitatHR::kernelUD(TripCoords, h=(Scale * 1000), grid=INPUTgrid, same4all=F)
image(KDE.Surface)
extendX
extendX <- max(diff(range(coordinates(TripCoords[,1])))*0.01, Scale*2000)
extendY <- max(diff(range(coordinates(TripCoords[,2])))*0.01, Scale*2000)
KDE.Surface <- estSpaceUse(DataGroup=Trips, Scale = HVALS$mag, UDLev = 95, Res=0.5, polyOut=T, plotIt = F)
extendX <- max(diff(range(coordinates(TripCoords[,1])))*0.01, Scale*2000)
extendY <- max(diff(range(coordinates(TripCoords[,2])))*0.01, Scale*2000)
minX <- min(coordinates(TripCoords)[,1]) - extendX
extendX <- max(diff(range(coordinates(TripCoords[,1])))*0.01, Scale*2000)
extendY <- max(diff(range(coordinates(TripCoords[,2])))*0.01, Scale*2000)
coordinates(TripCoords[,2])
TripCoords
TripCoords[,2]
extendX <- max(diff(range(coordinates(TripCoords)[,1]))*0.01, Scale*2000)
extendY <- max(diff(range(coordinates(TripCoords)[,2]))*0.01, Scale*2000)
extendX
extendY
coordinates(TripCoords)[,2]
range(coordinates(TripCoords)[,2])
diff(range(coordinates(TripCoords)[,2]))
diff(range(coordinates(TripCoords)[,1]))
diff(range(coordinates(TripCoords)[,2]))*0.01
diff(range(coordinates(TripCoords)[,1]))*0.01
extendX <- max(diff(range(coordinates(TripCoords)[,1]))*0.05, Scale*2000)
extendY <- max(diff(range(coordinates(TripCoords)[,2]))*0.05, Scale*2000)
extendX
extendY
minX <- min(coordinates(TripCoords)[,1]) - extendX
maxX <- max(coordinates(TripCoords)[,1]) + extendX
minY <- min(coordinates(TripCoords)[,2]) - extendY
maxY <- max(coordinates(TripCoords)[,2]) + extendY
Res <- ( max(abs(minX-maxX)/500, abs( minY-maxY )/500) )/1000
### specify sequence of grid cells and combine to SpatialPixels
xrange <- seq(minX,maxX, by = Res*1000) #diff(range(coordinates(TripCoords)[,1]))/Res)   ### if Res should be provided in km we need to change this
yrange <- seq(minY,maxY, by = Res*1000) #diff(range(coordinates(TripCoords)[,2]))/Res)   ### if Res should be provided in km we need to change this
grid.locs <- expand.grid(x=xrange,y=yrange)
INPUTgrid <- SpatialPixels(SpatialPoints(grid.locs), proj4string=proj4string(TripCoords))
Scale < Res*0.1228
KDE.Surface <- adehabitatHR::kernelUD(TripCoords, h=(Scale * 1000), grid=INPUTgrid, same4all=F)
image(KDE.Surface)
minX
min(coordinates(TripCoords)[,1])
extendX
extendY
KDE.Sp <- adehabitatHR::getverticeshr(KDE.Surface, percent = UDLev,unin = "m", unout = "km2")
image(KDE.Sp)
plot(KDE.Sp)
KDE.Surface <- estSpaceUse(DataGroup=Trips, Scale = HVALS$mag, UDLev = 50, Res=0.5, polyOut=T, plotIt = F)
library(track2KBA)
library(dplyr)
library(track2KBA)
data("boobies")
tracks <- boobies
colony <- tracks[1,] %>% dplyr::select(lon_colony,lat_colony) %>%
rename(Longitude=lon_colony,Latitude=lat_colony)
tracks <- formatFields(tracks, field_ID = "track_id", field_Lat="latitude", field_Lon="longitude", field_Date="date_gmt", field_Time="time_gmt")
## 2a. ####
### tripSplit (split tracks in to discrete trips [and optionally filter]) ~~~~~~~~~~~~~
Trips <- tripSplit(tracks, Colony=colony, InnerBuff=5, ReturnBuff=10, Duration=1, plotit=T, Nests = F, rmColLocs = T, cleanDF=T)
## 2b. ####
### tripSummary (summary of trip movements, by individual) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
trip_distances <- tripSummary(Trips, Colony = colony, Nests = F)
trip_distances
KDE.Surface <- estSpaceUse(DataGroup=Trips, Scale = HVALS$mag, UDLev = 50, Res=0.5, polyOut=T, plotIt = F)
debug(repAssess)
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=2, BootTable = F, avgMethod="mean", Ncores = 7)
class(KDE)
class(KDE$KDE.Surface)
library(dplyr)
library(track2KBA)
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=10, UDLev=50, avgMethod="mean", Ncores = 5)
undebug(repAssess)
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=10, UDLev=50, avgMethod="mean", Ncores = 5)
repr
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=5, BootTable = F, avgMethod="weighted", Ncores = 11)
### repAssess (Assess representativeness of tracked sample ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
before <- Sys.time()
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=5, BootTable = F, avgMethod="weighted", Ncores = 11)
# repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=10, UDLev=50, avgMethod="mean", Ncores = 5)
Sys.time() - before
repr
before <- Sys.time()
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=50, BootTable = F, avgMethod="weighted", Ncores = 11)
# repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=10, UDLev=50, avgMethod="mean", Ncores = 5)
Sys.time() - before
repr
?repAssess
debug(repAssess)
# repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=50, BootTable = F, avgMethod="weighted", Ncores = 11)
repr <- repAssess(Trips, KDE=KDE.Surface, Iteration=2, UDLev=50, avgMethod="mean", Ncores = 5)
Result
Result$InclusionMean
repr
